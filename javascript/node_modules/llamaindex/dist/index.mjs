var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __reflectGet = Reflect.get;
var __knownSymbol = (name, symbol) => {
  if (symbol = Symbol[name])
    return symbol;
  throw Error("Symbol." + name + " is not defined");
};
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b || (b = {}))
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};
var __spreadProps = (a, b) => __defProps(a, __getOwnPropDescs(b));
var __require = /* @__PURE__ */ ((x) => typeof require !== "undefined" ? require : typeof Proxy !== "undefined" ? new Proxy(x, {
  get: (a, b) => (typeof require !== "undefined" ? require : a)[b]
}) : x)(function(x) {
  if (typeof require !== "undefined")
    return require.apply(this, arguments);
  throw Error('Dynamic require of "' + x + '" is not supported');
});
var __objRest = (source, exclude) => {
  var target = {};
  for (var prop in source)
    if (__hasOwnProp.call(source, prop) && exclude.indexOf(prop) < 0)
      target[prop] = source[prop];
  if (source != null && __getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(source)) {
      if (exclude.indexOf(prop) < 0 && __propIsEnum.call(source, prop))
        target[prop] = source[prop];
    }
  return target;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __reExport = (target, mod, secondTarget) => (__copyProps(target, mod, "default"), secondTarget && __copyProps(secondTarget, mod, "default"));
var __superGet = (cls, obj, key) => __reflectGet(__getProtoOf(cls), key, obj);
var __async = (__this, __arguments, generator) => {
  return new Promise((resolve, reject) => {
    var fulfilled = (value) => {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    };
    var rejected = (value) => {
      try {
        step(generator.throw(value));
      } catch (e) {
        reject(e);
      }
    };
    var step = (x) => x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
    step((generator = generator.apply(__this, __arguments)).next());
  });
};
var __await = function(promise, isYieldStar) {
  this[0] = promise;
  this[1] = isYieldStar;
};
var __asyncGenerator = (__this, __arguments, generator) => {
  var resume = (k, v, yes, no) => {
    try {
      var x = generator[k](v), isAwait = (v = x.value) instanceof __await, done = x.done;
      Promise.resolve(isAwait ? v[0] : v).then((y) => isAwait ? resume(k === "return" ? k : "next", v[1] ? { done: y.done, value: y.value } : y, yes, no) : yes({ value: y, done })).catch((e) => resume("throw", e, yes, no));
    } catch (e) {
      no(e);
    }
  };
  var method = (k) => it[k] = (x) => new Promise((yes, no) => resume(k, x, yes, no));
  var it = {};
  return generator = generator.apply(__this, __arguments), it[Symbol.asyncIterator] = () => it, method("next"), method("throw"), method("return"), it;
};
var __yieldStar = (value) => {
  var obj = value[__knownSymbol("asyncIterator")];
  var isAwait = false;
  var method;
  var it = {};
  if (obj == null) {
    obj = value[__knownSymbol("iterator")]();
    method = (k) => it[k] = (x) => obj[k](x);
  } else {
    obj = obj.call(value);
    method = (k) => it[k] = (v) => {
      if (isAwait) {
        isAwait = false;
        if (k === "throw")
          throw v;
        return v;
      }
      isAwait = true;
      return {
        done: false,
        value: new __await(new Promise((resolve) => {
          var x = obj[k](v);
          if (!(x instanceof Object))
            throw TypeError("Object expected");
          resolve(x);
        }), 1)
      };
    };
  }
  return it[__knownSymbol("iterator")] = () => it, method("next"), "throw" in obj ? method("throw") : it.throw = (x) => {
    throw x;
  }, "return" in obj && method("return"), it;
};
var __forAwait = (obj, it, method) => (it = obj[__knownSymbol("asyncIterator")]) ? it.call(obj) : (obj = obj[__knownSymbol("iterator")](), it = {}, method = (key, fn) => (fn = obj[key]) && (it[key] = (arg) => new Promise((yes, no, done) => (arg = fn.call(obj, arg), done = arg.done, Promise.resolve(arg.value).then((value) => yes({ value, done }), no)))), method("next"), method("return"), it);

// src/callbacks/CallbackManager.ts
var CallbackManager = class {
  constructor(handlers) {
    this.onLLMStream = handlers == null ? void 0 : handlers.onLLMStream;
    this.onRetrieve = handlers == null ? void 0 : handlers.onRetrieve;
  }
};

// src/ChatEngine.ts
import { v4 as uuidv43 } from "uuid";

// src/GlobalsHelper.ts
import cl100k_base from "tiktoken/encoders/cl100k_base.json";
import { Tiktoken } from "tiktoken/lite";
import { v4 as uuidv4 } from "uuid";
var Tokenizers = /* @__PURE__ */ ((Tokenizers2) => {
  Tokenizers2["CL100K_BASE"] = "cl100k_base";
  return Tokenizers2;
})(Tokenizers || {});
var GlobalsHelper = class {
  constructor() {
    this.defaultTokenizer = null;
  }
  initDefaultTokenizer() {
    const encoding = new Tiktoken(
      cl100k_base.bpe_ranks,
      cl100k_base.special_tokens,
      cl100k_base.pat_str
    );
    this.defaultTokenizer = {
      encode: (text) => {
        return encoding.encode(text);
      },
      decode: (tokens) => {
        return new TextDecoder().decode(encoding.decode(tokens));
      }
    };
  }
  tokenizer(encoding) {
    if (encoding && encoding !== "cl100k_base" /* CL100K_BASE */) {
      throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
    }
    if (!this.defaultTokenizer) {
      this.initDefaultTokenizer();
    }
    return this.defaultTokenizer.encode.bind(this.defaultTokenizer);
  }
  tokenizerDecoder(encoding) {
    if (encoding && encoding !== "cl100k_base" /* CL100K_BASE */) {
      throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
    }
    if (!this.defaultTokenizer) {
      this.initDefaultTokenizer();
    }
    return this.defaultTokenizer.decode.bind(this.defaultTokenizer);
  }
  createEvent({
    parentEvent,
    type,
    tags
  }) {
    return {
      id: uuidv4(),
      type,
      // inherit parent tags if tags not set
      tags: tags || (parentEvent == null ? void 0 : parentEvent.tags),
      parentId: parentEvent == null ? void 0 : parentEvent.id
    };
  }
};
var globalsHelper = new GlobalsHelper();

// src/llm/anthropic.ts
import Anthropic, {
  AI_PROMPT,
  HUMAN_PROMPT
} from "@anthropic-ai/sdk";
import _ from "lodash";
var AnthropicSession = class {
  constructor(options = {}) {
    if (!options.apiKey) {
      if (typeof process !== void 0) {
        options.apiKey = process.env.ANTHROPIC_API_KEY;
      }
    }
    if (!options.apiKey) {
      throw new Error("Set Anthropic Key in ANTHROPIC_API_KEY env variable");
    }
    this.anthropic = new Anthropic(options);
  }
};
var defaultAnthropicSession = [];
function getAnthropicSession(options = {}) {
  var _a;
  let session = (_a = defaultAnthropicSession.find((session2) => {
    return _.isEqual(session2.options, options);
  })) == null ? void 0 : _a.session;
  if (!session) {
    session = new AnthropicSession(options);
    defaultAnthropicSession.push({ session, options });
  }
  return session;
}
var ANTHROPIC_HUMAN_PROMPT = HUMAN_PROMPT;
var ANTHROPIC_AI_PROMPT = AI_PROMPT;

// src/llm/azure.ts
var ALL_AZURE_OPENAI_CHAT_MODELS = {
  "gpt-35-turbo": { contextWindow: 4096, openAIModel: "gpt-3.5-turbo" },
  "gpt-35-turbo-16k": {
    contextWindow: 16384,
    openAIModel: "gpt-3.5-turbo-16k"
  },
  "gpt-4": { contextWindow: 8192, openAIModel: "gpt-4" },
  "gpt-4-32k": { contextWindow: 32768, openAIModel: "gpt-4-32k" }
};
var ALL_AZURE_OPENAI_EMBEDDING_MODELS = {
  "text-embedding-ada-002": {
    dimensions: 1536,
    openAIModel: "text-embedding-ada-002",
    maxTokens: 8191
  }
};
var DEFAULT_API_VERSION = "2023-05-15";
function getAzureConfigFromEnv(init) {
  var _a, _b, _c, _d, _e, _f, _g, _h, _i, _j, _k, _l, _m;
  return {
    apiKey: (_c = (_b = (_a = init == null ? void 0 : init.apiKey) != null ? _a : process.env.AZURE_OPENAI_KEY) != null ? _b : (
      // From Azure docs
      process.env.OPENAI_API_KEY
    )) != null ? _c : (
      // Python compatible
      process.env.AZURE_OPENAI_API_KEY
    ),
    // LCJS compatible
    endpoint: (_f = (_e = (_d = init == null ? void 0 : init.endpoint) != null ? _d : process.env.AZURE_OPENAI_ENDPOINT) != null ? _e : (
      // From Azure docs
      process.env.OPENAI_API_BASE
    )) != null ? _f : (
      // Python compatible
      process.env.AZURE_OPENAI_API_INSTANCE_NAME
    ),
    // LCJS compatible
    apiVersion: (_j = (_i = (_h = (_g = init == null ? void 0 : init.apiVersion) != null ? _g : process.env.AZURE_OPENAI_API_VERSION) != null ? _h : (
      // From Azure docs
      process.env.OPENAI_API_VERSION
    )) != null ? _i : (
      // Python compatible
      process.env.AZURE_OPENAI_API_VERSION
    )) != null ? _j : (
      // LCJS compatible
      DEFAULT_API_VERSION
    ),
    deploymentName: (_m = (_l = (_k = init == null ? void 0 : init.deploymentName) != null ? _k : process.env.AZURE_OPENAI_DEPLOYMENT) != null ? _l : (
      // From Azure docs
      process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME
    )) != null ? _m : (
      // LCJS compatible
      init == null ? void 0 : init.model
    )
    // Fall back to model name, Python compatible
  };
}
function getAzureBaseUrl(config) {
  return `${config.endpoint}/openai/deployments/${config.deploymentName}`;
}
function getAzureModel(openAIModel) {
  for (const [key, value] of Object.entries(
    ALL_AZURE_OPENAI_EMBEDDING_MODELS
  )) {
    if (value.openAIModel === openAIModel) {
      return key;
    }
  }
  for (const [key, value] of Object.entries(ALL_AZURE_OPENAI_CHAT_MODELS)) {
    if (value.openAIModel === openAIModel) {
      return key;
    }
  }
  throw new Error(`Unknown model: ${openAIModel}`);
}
function shouldUseAzure() {
  return process.env.AZURE_OPENAI_ENDPOINT || process.env.AZURE_OPENAI_API_INSTANCE_NAME || process.env.OPENAI_API_TYPE === "azure";
}

// src/llm/openai.ts
import _2 from "lodash";
import OpenAI from "openai";
var AzureOpenAI = class extends OpenAI {
  authHeaders() {
    return { "api-key": this.apiKey };
  }
};
var OpenAISession = class {
  constructor(options = {}) {
    if (!options.apiKey) {
      if (typeof process !== void 0) {
        options.apiKey = process.env.OPENAI_API_KEY;
      }
    }
    if (!options.apiKey) {
      throw new Error("Set OpenAI Key in OPENAI_API_KEY env variable");
    }
    if (options.azure) {
      this.openai = new AzureOpenAI(options);
    } else {
      this.openai = new OpenAI(options);
    }
  }
};
var defaultOpenAISession = [];
function getOpenAISession(options = {}) {
  var _a;
  let session = (_a = defaultOpenAISession.find((session2) => {
    return _2.isEqual(session2.options, options);
  })) == null ? void 0 : _a.session;
  if (!session) {
    session = new OpenAISession(options);
    defaultOpenAISession.push({ session, options });
  }
  return session;
}

// src/llm/portkey.ts
import _3 from "lodash";
import { Portkey } from "portkey-ai";
var readEnv = (env, default_val) => {
  var _a, _b;
  if (typeof process !== "undefined") {
    return (_b = (_a = process.env) == null ? void 0 : _a[env]) != null ? _b : default_val;
  }
  return default_val;
};
var PortkeySession = class {
  constructor(options = {}) {
    if (!options.apiKey) {
      options.apiKey = readEnv("PORTKEY_API_KEY");
    }
    if (!options.baseURL) {
      options.baseURL = readEnv("PORTKEY_BASE_URL", "https://api.portkey.ai");
    }
    this.portkey = new Portkey({});
    this.portkey.llms = [{}];
    if (!options.apiKey) {
      throw new Error("Set Portkey ApiKey in PORTKEY_API_KEY env variable");
    }
    this.portkey = new Portkey(options);
  }
};
var defaultPortkeySession = [];
function getPortkeySession(options = {}) {
  var _a;
  let session = (_a = defaultPortkeySession.find((session2) => {
    return _3.isEqual(session2.options, options);
  })) == null ? void 0 : _a.session;
  if (!session) {
    session = new PortkeySession(options);
    defaultPortkeySession.push({ session, options });
  }
  return session;
}

// src/llm/replicate.ts
var replicate_exports = {};
__export(replicate_exports, {
  ReplicateSession: () => ReplicateSession,
  getReplicateSession: () => getReplicateSession
});
__reExport(replicate_exports, openai_star);
import Replicate from "replicate";
import * as openai_star from "openai";
var ReplicateSession = class {
  constructor(replicateKey = null) {
    this.replicateKey = null;
    if (replicateKey) {
      this.replicateKey = replicateKey;
    } else if (process.env.REPLICATE_API_TOKEN) {
      this.replicateKey = process.env.REPLICATE_API_TOKEN;
    } else {
      throw new Error(
        "Set Replicate token in REPLICATE_API_TOKEN env variable"
      );
    }
    this.replicate = new Replicate({ auth: this.replicateKey });
  }
};
var defaultReplicateSession = null;
function getReplicateSession(replicateKey = null) {
  if (!defaultReplicateSession) {
    defaultReplicateSession = new ReplicateSession(replicateKey);
  }
  return defaultReplicateSession;
}

// src/llm/LLM.ts
var GPT4_MODELS = {
  "gpt-4": { contextWindow: 8192 },
  "gpt-4-32k": { contextWindow: 32768 }
};
var TURBO_MODELS = {
  "gpt-3.5-turbo": { contextWindow: 4096 },
  "gpt-3.5-turbo-16k": { contextWindow: 16384 }
};
var ALL_AVAILABLE_OPENAI_MODELS = __spreadValues(__spreadValues({}, GPT4_MODELS), TURBO_MODELS);
var OpenAI2 = class {
  constructor(init) {
    this.hasStreaming = true;
    // OpenAI session params
    this.apiKey = void 0;
    var _a, _b, _c, _d, _e, _f, _g, _h, _i;
    this.model = (_a = init == null ? void 0 : init.model) != null ? _a : "gpt-3.5-turbo";
    this.temperature = (_b = init == null ? void 0 : init.temperature) != null ? _b : 0.1;
    this.topP = (_c = init == null ? void 0 : init.topP) != null ? _c : 1;
    this.maxTokens = (_d = init == null ? void 0 : init.maxTokens) != null ? _d : void 0;
    this.maxRetries = (_e = init == null ? void 0 : init.maxRetries) != null ? _e : 10;
    this.timeout = (_f = init == null ? void 0 : init.timeout) != null ? _f : 60 * 1e3;
    this.additionalChatOptions = init == null ? void 0 : init.additionalChatOptions;
    this.additionalSessionOptions = init == null ? void 0 : init.additionalSessionOptions;
    if ((init == null ? void 0 : init.azure) || shouldUseAzure()) {
      const azureConfig = getAzureConfigFromEnv(__spreadProps(__spreadValues({}, init == null ? void 0 : init.azure), {
        model: getAzureModel(this.model)
      }));
      if (!azureConfig.apiKey) {
        throw new Error(
          "Azure API key is required for OpenAI Azure models. Please set the AZURE_OPENAI_KEY environment variable."
        );
      }
      this.apiKey = azureConfig.apiKey;
      this.session = (_g = init == null ? void 0 : init.session) != null ? _g : getOpenAISession(__spreadValues({
        azure: true,
        apiKey: this.apiKey,
        baseURL: getAzureBaseUrl(azureConfig),
        maxRetries: this.maxRetries,
        timeout: this.timeout,
        defaultQuery: { "api-version": azureConfig.apiVersion }
      }, this.additionalSessionOptions));
    } else {
      this.apiKey = (_h = init == null ? void 0 : init.apiKey) != null ? _h : void 0;
      this.session = (_i = init == null ? void 0 : init.session) != null ? _i : getOpenAISession(__spreadValues({
        apiKey: this.apiKey,
        maxRetries: this.maxRetries,
        timeout: this.timeout
      }, this.additionalSessionOptions));
    }
    this.callbackManager = init == null ? void 0 : init.callbackManager;
  }
  get metadata() {
    return {
      model: this.model,
      temperature: this.temperature,
      topP: this.topP,
      maxTokens: this.maxTokens,
      contextWindow: ALL_AVAILABLE_OPENAI_MODELS[this.model].contextWindow,
      tokenizer: "cl100k_base" /* CL100K_BASE */
    };
  }
  tokens(messages) {
    const tokenizer = globalsHelper.tokenizer(this.metadata.tokenizer);
    const tokensPerMessage = 3;
    let numTokens = 0;
    for (const message of messages) {
      numTokens += tokensPerMessage;
      for (const value of Object.values(message)) {
        numTokens += tokenizer(value).length;
      }
    }
    numTokens += 3;
    return numTokens;
  }
  mapMessageType(messageType) {
    switch (messageType) {
      case "user":
        return "user";
      case "assistant":
        return "assistant";
      case "system":
        return "system";
      case "function":
        return "function";
      default:
        return "user";
    }
  }
  chat(messages, parentEvent, streaming) {
    return __async(this, null, function* () {
      var _a, _b;
      const baseRequestParams = __spreadValues({
        model: this.model,
        temperature: this.temperature,
        max_tokens: this.maxTokens,
        messages: messages.map((message) => ({
          role: this.mapMessageType(message.role),
          content: message.content
        })),
        top_p: this.topP
      }, this.additionalChatOptions);
      if (streaming) {
        if (!this.hasStreaming) {
          throw Error("No streaming support for this LLM.");
        }
        return this.streamChat(messages, parentEvent);
      }
      const response = yield this.session.openai.chat.completions.create(__spreadProps(__spreadValues({}, baseRequestParams), {
        stream: false
      }));
      const content = (_b = (_a = response.choices[0].message) == null ? void 0 : _a.content) != null ? _b : "";
      return {
        message: { content, role: response.choices[0].message.role }
      };
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      return this.chat(
        [{ content: prompt, role: "user" }],
        parentEvent,
        streaming
      );
    });
  }
  //We can wrap a stream in a generator to add some additional logging behavior
  //For future edits: syntax for generator type is <typeof Yield, typeof Return, typeof Accept>
  //"typeof Accept" refers to what types you'll accept when you manually call generator.next(<AcceptType>)
  streamChat(messages, parentEvent) {
    return __asyncGenerator(this, null, function* () {
      var _a;
      const baseRequestParams = __spreadValues({
        model: this.model,
        temperature: this.temperature,
        max_tokens: this.maxTokens,
        messages: messages.map((message) => ({
          role: this.mapMessageType(message.role),
          content: message.content
        })),
        top_p: this.topP
      }, this.additionalChatOptions);
      const onLLMStream = ((_a = this.callbackManager) == null ? void 0 : _a.onLLMStream) ? this.callbackManager.onLLMStream : () => {
      };
      const chunk_stream = yield new __await(this.session.openai.chat.completions.create(__spreadProps(__spreadValues({}, baseRequestParams), {
        stream: true
      })));
      const event = parentEvent ? parentEvent : {
        id: "unspecified",
        type: "llmPredict"
      };
      var idx_counter = 0;
      try {
        for (var iter = __forAwait(chunk_stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          part.choices[0].index = idx_counter;
          const is_done = part.choices[0].finish_reason === "stop" ? true : false;
          const stream_callback = {
            event,
            index: idx_counter,
            isDone: is_done,
            token: part
          };
          onLLMStream(stream_callback);
          idx_counter++;
          yield part.choices[0].delta.content ? part.choices[0].delta.content : "";
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return;
    });
  }
  //streamComplete doesn't need to be async because it's child function is already async
  streamComplete(query, parentEvent) {
    return this.streamChat([{ content: query, role: "user" }], parentEvent);
  }
};
var ALL_AVAILABLE_LLAMADEUCE_MODELS = {
  "Llama-2-70b-chat-old": {
    contextWindow: 4096,
    replicateApi: "replicate/llama70b-v2-chat:e951f18578850b652510200860fc4ea62b3b16fac280f83ff32282f87bbd2e48"
    //^ Previous 70b model. This is also actually 4 bit, although not exllama.
  },
  "Llama-2-70b-chat-4bit": {
    contextWindow: 4096,
    replicateApi: "replicate/llama70b-v2-chat:2c1608e18606fad2812020dc541930f2d0495ce32eee50074220b87300bc16e1"
    //^ Model is based off of exllama 4bit.
  },
  "Llama-2-13b-chat": {
    contextWindow: 4096,
    replicateApi: "a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5"
  },
  //^ Last known good 13b non-quantized model. In future versions they add the SYS and INST tags themselves
  "Llama-2-13b-chat-4bit": {
    contextWindow: 4096,
    replicateApi: "a16z-infra/llama13b-v2-chat:2a7f981751ec7fdf87b5b91ad4db53683a98082e9ff7bfd12c8cd5ea85980a52"
  },
  "Llama-2-7b-chat": {
    contextWindow: 4096,
    replicateApi: "a16z-infra/llama7b-v2-chat:4f0a4744c7295c024a1de15e1a63c880d3da035fa1f49bfd344fe076074c8eea"
    //^ Last (somewhat) known good 7b non-quantized model. In future versions they add the SYS and INST
    // tags themselves
    // https://github.com/replicate/cog-llama-template/commit/fa5ce83912cf82fc2b9c01a4e9dc9bff6f2ef137
    // Problem is that they fix the max_new_tokens issue in the same commit. :-(
  },
  "Llama-2-7b-chat-4bit": {
    contextWindow: 4096,
    replicateApi: "a16z-infra/llama7b-v2-chat:4f0b260b6a13eb53a6b1891f089d57c08f41003ae79458be5011303d81a394dc"
  }
};
var DeuceChatStrategy = /* @__PURE__ */ ((DeuceChatStrategy2) => {
  DeuceChatStrategy2["A16Z"] = "a16z";
  DeuceChatStrategy2["META"] = "meta";
  DeuceChatStrategy2["METAWBOS"] = "metawbos";
  DeuceChatStrategy2["REPLICATE4BIT"] = "replicate4bit";
  return DeuceChatStrategy2;
})(DeuceChatStrategy || {});
var LlamaDeuce = class {
  constructor(init) {
    var _a, _b, _c, _d, _e, _f, _g;
    this.model = (_a = init == null ? void 0 : init.model) != null ? _a : "Llama-2-70b-chat-4bit";
    this.chatStrategy = (_b = init == null ? void 0 : init.chatStrategy) != null ? _b : this.model.endsWith("4bit") ? "replicate4bit" /* REPLICATE4BIT */ : "metawbos" /* METAWBOS */;
    this.temperature = (_c = init == null ? void 0 : init.temperature) != null ? _c : 0.1;
    this.topP = (_d = init == null ? void 0 : init.topP) != null ? _d : 1;
    this.maxTokens = (_e = init == null ? void 0 : init.maxTokens) != null ? _e : ALL_AVAILABLE_LLAMADEUCE_MODELS[this.model].contextWindow;
    this.replicateSession = (_f = init == null ? void 0 : init.replicateSession) != null ? _f : new ReplicateSession();
    this.hasStreaming = (_g = init == null ? void 0 : init.hasStreaming) != null ? _g : false;
  }
  tokens(messages) {
    throw new Error("Method not implemented.");
  }
  get metadata() {
    return {
      model: this.model,
      temperature: this.temperature,
      topP: this.topP,
      maxTokens: this.maxTokens,
      contextWindow: ALL_AVAILABLE_LLAMADEUCE_MODELS[this.model].contextWindow,
      tokenizer: void 0
    };
  }
  mapMessagesToPrompt(messages) {
    if (this.chatStrategy === "a16z" /* A16Z */) {
      return this.mapMessagesToPromptA16Z(messages);
    } else if (this.chatStrategy === "meta" /* META */) {
      return this.mapMessagesToPromptMeta(messages);
    } else if (this.chatStrategy === "metawbos" /* METAWBOS */) {
      return this.mapMessagesToPromptMeta(messages, { withBos: true });
    } else if (this.chatStrategy === "replicate4bit" /* REPLICATE4BIT */) {
      return this.mapMessagesToPromptMeta(messages, { replicate4Bit: true });
    } else {
      return this.mapMessagesToPromptMeta(messages);
    }
  }
  mapMessagesToPromptA16Z(messages) {
    return {
      prompt: messages.reduce((acc, message) => {
        return (acc && `${acc}

`) + `${this.mapMessageTypeA16Z(message.role)}${message.content}`;
      }, "") + "\n\nAssistant:",
      //^ Here we're differing from A16Z by omitting the space. Generally spaces at the end of prompts decrease performance due to tokenization
      systemPrompt: void 0
    };
  }
  mapMessageTypeA16Z(messageType) {
    switch (messageType) {
      case "user":
        return "User: ";
      case "assistant":
        return "Assistant: ";
      case "system":
        return "";
      default:
        throw new Error("Unsupported LlamaDeuce message type");
    }
  }
  mapMessagesToPromptMeta(messages, opts) {
    const { withBos = false, replicate4Bit = false } = opts != null ? opts : {};
    const DEFAULT_SYSTEM_PROMPT = `You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.

If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.`;
    const B_SYS = "<<SYS>>\n";
    const E_SYS = "\n<</SYS>>\n\n";
    const B_INST = "[INST]";
    const E_INST = "[/INST]";
    const BOS = "<s>";
    const EOS = "</s>";
    if (messages.length === 0) {
      return { prompt: "", systemPrompt: void 0 };
    }
    messages = [...messages];
    let systemPrompt = void 0;
    if (messages[0].role === "system") {
      const systemMessage = messages.shift();
      if (replicate4Bit) {
        systemPrompt = systemMessage.content;
      } else {
        const systemStr = `${B_SYS}${systemMessage.content}${E_SYS}`;
        if (messages[0].role !== "user") {
          throw new Error(
            "LlamaDeuce: if there is a system message, the second message must be a user message."
          );
        }
        const userContent = messages[0].content;
        messages[0].content = `${systemStr}${userContent}`;
      }
    } else {
      if (!replicate4Bit) {
        messages[0].content = `${B_SYS}${DEFAULT_SYSTEM_PROMPT}${E_SYS}${messages[0].content}`;
      }
    }
    return {
      prompt: messages.reduce((acc, message, index) => {
        if (index % 2 === 0) {
          return `${acc}${withBos ? BOS : ""}${B_INST} ${message.content.trim()} ${E_INST}`;
        } else {
          return `${acc} ${message.content.trim()} ` + (withBos ? EOS : "");
        }
      }, ""),
      systemPrompt
    };
  }
  chat(messages, _parentEvent, streaming) {
    return __async(this, null, function* () {
      const api = ALL_AVAILABLE_LLAMADEUCE_MODELS[this.model].replicateApi;
      const { prompt, systemPrompt } = this.mapMessagesToPrompt(messages);
      const replicateOptions = {
        input: {
          prompt,
          system_prompt: systemPrompt,
          temperature: this.temperature,
          top_p: this.topP
        }
      };
      if (this.model.endsWith("4bit")) {
        replicateOptions.input.max_new_tokens = this.maxTokens;
      } else {
        replicateOptions.input.max_length = this.maxTokens;
      }
      const response = yield this.replicateSession.replicate.run(
        api,
        replicateOptions
      );
      return {
        message: {
          content: response.join("").trimStart(),
          //^ We need to do this because Replicate returns a list of strings (for streaming functionality which is not exposed by the run function)
          role: "assistant"
        }
      };
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      return this.chat([{ content: prompt, role: "user" }], parentEvent);
    });
  }
};
var ALL_AVAILABLE_ANTHROPIC_MODELS = {
  // both models have 100k context window, see https://docs.anthropic.com/claude/reference/selecting-a-model
  "claude-2": { contextWindow: 1e5 },
  "claude-instant-1": { contextWindow: 1e5 }
};
var Anthropic2 = class {
  constructor(init) {
    this.hasStreaming = true;
    // Anthropic session params
    this.apiKey = void 0;
    var _a, _b, _c, _d, _e, _f, _g, _h;
    this.model = (_a = init == null ? void 0 : init.model) != null ? _a : "claude-2";
    this.temperature = (_b = init == null ? void 0 : init.temperature) != null ? _b : 0.1;
    this.topP = (_c = init == null ? void 0 : init.topP) != null ? _c : 0.999;
    this.maxTokens = (_d = init == null ? void 0 : init.maxTokens) != null ? _d : void 0;
    this.apiKey = (_e = init == null ? void 0 : init.apiKey) != null ? _e : void 0;
    this.maxRetries = (_f = init == null ? void 0 : init.maxRetries) != null ? _f : 10;
    this.timeout = (_g = init == null ? void 0 : init.timeout) != null ? _g : 60 * 1e3;
    this.session = (_h = init == null ? void 0 : init.session) != null ? _h : getAnthropicSession({
      apiKey: this.apiKey,
      maxRetries: this.maxRetries,
      timeout: this.timeout
    });
    this.callbackManager = init == null ? void 0 : init.callbackManager;
  }
  tokens(messages) {
    throw new Error("Method not implemented.");
  }
  get metadata() {
    return {
      model: this.model,
      temperature: this.temperature,
      topP: this.topP,
      maxTokens: this.maxTokens,
      contextWindow: ALL_AVAILABLE_ANTHROPIC_MODELS[this.model].contextWindow,
      tokenizer: void 0
    };
  }
  mapMessagesToPrompt(messages) {
    return messages.reduce((acc, message) => {
      return acc + `${message.role === "assistant" ? ANTHROPIC_AI_PROMPT : ANTHROPIC_HUMAN_PROMPT} ${message.content} `;
    }, "") + ANTHROPIC_AI_PROMPT;
  }
  chat(messages, parentEvent, streaming) {
    return __async(this, null, function* () {
      var _a;
      if (streaming) {
        if (!this.hasStreaming) {
          throw Error("No streaming support for this LLM.");
        }
        return this.streamChat(messages, parentEvent);
      }
      const response = yield this.session.anthropic.completions.create({
        model: this.model,
        prompt: this.mapMessagesToPrompt(messages),
        max_tokens_to_sample: (_a = this.maxTokens) != null ? _a : 1e5,
        temperature: this.temperature,
        top_p: this.topP
      });
      return {
        message: { content: response.completion.trimStart(), role: "assistant" }
        //^ We're trimming the start because Anthropic often starts with a space in the response
        // That space will be re-added when we generate the next prompt.
      };
    });
  }
  streamChat(messages, parentEvent) {
    return __asyncGenerator(this, null, function* () {
      var _a;
      const stream = yield new __await(this.session.anthropic.completions.create({
        model: this.model,
        prompt: this.mapMessagesToPrompt(messages),
        max_tokens_to_sample: (_a = this.maxTokens) != null ? _a : 1e5,
        temperature: this.temperature,
        top_p: this.topP,
        stream: true
      }));
      var idx_counter = 0;
      try {
        for (var iter = __forAwait(stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          idx_counter++;
          yield part.completion;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return;
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      if (streaming) {
        return this.streamComplete(prompt, parentEvent);
      }
      return this.chat(
        [{ content: prompt, role: "user" }],
        parentEvent,
        streaming
      );
    });
  }
  streamComplete(prompt, parentEvent) {
    return this.streamChat([{ content: prompt, role: "user" }], parentEvent);
  }
};
var Portkey2 = class {
  constructor(init) {
    this.hasStreaming = true;
    this.apiKey = void 0;
    this.baseURL = void 0;
    this.mode = void 0;
    this.llms = void 0;
    this.apiKey = init == null ? void 0 : init.apiKey;
    this.baseURL = init == null ? void 0 : init.baseURL;
    this.mode = init == null ? void 0 : init.mode;
    this.llms = init == null ? void 0 : init.llms;
    this.session = getPortkeySession({
      apiKey: this.apiKey,
      baseURL: this.baseURL,
      llms: this.llms,
      mode: this.mode
    });
    this.callbackManager = init == null ? void 0 : init.callbackManager;
  }
  tokens(messages) {
    throw new Error("Method not implemented.");
  }
  get metadata() {
    throw new Error("metadata not implemented for Portkey");
  }
  chat(messages, parentEvent, streaming, params) {
    return __async(this, null, function* () {
      var _a, _b, _c;
      if (streaming) {
        return this.streamChat(messages, parentEvent, params);
      } else {
        const resolvedParams = params || {};
        const response = yield this.session.portkey.chatCompletions.create(__spreadValues({
          messages
        }, resolvedParams));
        const content = (_b = (_a = response.choices[0].message) == null ? void 0 : _a.content) != null ? _b : "";
        const role = ((_c = response.choices[0].message) == null ? void 0 : _c.role) || "assistant";
        return { message: { content, role } };
      }
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      return this.chat(
        [{ content: prompt, role: "user" }],
        parentEvent,
        streaming
      );
    });
  }
  streamChat(messages, parentEvent, params) {
    return __asyncGenerator(this, null, function* () {
      var _a, _b, _c;
      const onLLMStream = ((_a = this.callbackManager) == null ? void 0 : _a.onLLMStream) ? this.callbackManager.onLLMStream : () => {
      };
      const chunkStream = yield new __await(this.session.portkey.chatCompletions.create(__spreadProps(__spreadValues({
        messages
      }, params), {
        stream: true
      })));
      const event = parentEvent ? parentEvent : {
        id: "unspecified",
        type: "llmPredict"
      };
      var idx_counter = 0;
      try {
        for (var iter = __forAwait(chunkStream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          part.choices[0].index = idx_counter;
          const is_done = part.choices[0].finish_reason === "stop" ? true : false;
          const stream_callback = {
            event,
            index: idx_counter,
            isDone: is_done
            // token: part,
          };
          onLLMStream(stream_callback);
          idx_counter++;
          yield (_c = (_b = part.choices[0].delta) == null ? void 0 : _b.content) != null ? _c : "";
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return;
    });
  }
  streamComplete(query, parentEvent) {
    return this.streamChat([{ content: query, role: "user" }], parentEvent);
  }
};

// src/Prompt.ts
var defaultTextQaPrompt = ({ context = "", query = "" }) => {
  return `Context information is below.
---------------------
${context}
---------------------
Given the context information and not prior knowledge, answer the query.
Query: ${query}
Answer:`;
};
var defaultSummaryPrompt = ({ context = "" }) => {
  return `Write a summary of the following. Try to use only the information provided. Try to include as many key details as possible.


${context}


SUMMARY:"""
`;
};
var defaultRefinePrompt = ({
  query = "",
  existingAnswer = "",
  context = ""
}) => {
  return `The original query is as follows: ${query}
We have provided an existing answer: ${existingAnswer}
We have the opportunity to refine the existing answer (only if needed) with some more context below.
------------
${context}
------------
Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.
Refined Answer:`;
};
var defaultTreeSummarizePrompt = ({ context = "", query = "" }) => {
  return `Context information from multiple sources is below.
---------------------
${context}
---------------------
Given the information from multiple sources and not prior knowledge, answer the query.
Query: ${query}
Answer:`;
};
var defaultChoiceSelectPrompt = ({ context = "", query = "" }) => {
  return `A list of documents is shown below. Each document has a number next to it along 
with a summary of the document. A question is also provided.
Respond with the numbers of the documents
you should consult to answer the question, in order of relevance, as well
as the relevance score. The relevance score is a number from 1-10 based on
how relevant you think the document is to the question.
Do not include any documents that are not relevant to the question.
Example format:
Document 1:
<summary of document 1>

Document 2:
<summary of document 2>

...

Document 10:
<summary of document 10>

Question: <question>
Answer:
Doc: 9, Relevance: 7
Doc: 3, Relevance: 4
Doc: 7, Relevance: 3

Let's try this now:

${context}
Question: ${query}
Answer:`;
};
function buildToolsText(tools) {
  const toolsObj = tools.reduce((acc, tool) => {
    acc[tool.name] = tool.description;
    return acc;
  }, {});
  return JSON.stringify(toolsObj, null, 4);
}
var exampleTools = [
  {
    name: "uber_10k",
    description: "Provides information about Uber financials for year 2021"
  },
  {
    name: "lyft_10k",
    description: "Provides information about Lyft financials for year 2021"
  }
];
var exampleQueryStr = `Compare and contrast the revenue growth and EBITDA of Uber and Lyft for year 2021`;
var exampleOutput = [
  {
    subQuestion: "What is the revenue growth of Uber",
    toolName: "uber_10k"
  },
  {
    subQuestion: "What is the EBITDA of Uber",
    toolName: "uber_10k"
  },
  {
    subQuestion: "What is the revenue growth of Lyft",
    toolName: "lyft_10k"
  },
  {
    subQuestion: "What is the EBITDA of Lyft",
    toolName: "lyft_10k"
  }
];
var defaultSubQuestionPrompt = ({ toolsStr = "", queryStr = "" }) => {
  return `Given a user question, and a list of tools, output a list of relevant sub-questions that when composed can help answer the full user question:

# Example 1
<Tools>
\`\`\`json
${buildToolsText(exampleTools)}
\`\`\`

<User Question>
${exampleQueryStr}

<Output>
\`\`\`json
${JSON.stringify(exampleOutput, null, 4)}
\`\`\`

# Example 2
<Tools>
\`\`\`json
${toolsStr}
\`\`\`

<User Question>
${queryStr}

<Output>
`;
};
var defaultCondenseQuestionPrompt = ({
  chatHistory = "",
  question = ""
}) => {
  return `Given a conversation (between Human and Assistant) and a follow up message from Human, rewrite the message to be a standalone question that captures all relevant context from the conversation.

<Chat History>
${chatHistory}

<Follow Up Message>
${question}

<Standalone question>
`;
};
function messagesToHistoryStr(messages) {
  return messages.reduce((acc, message) => {
    acc += acc ? "\n" : "";
    if (message.role === "user") {
      acc += `Human: ${message.content}`;
    } else {
      acc += `Assistant: ${message.content}`;
    }
    return acc;
  }, "");
}
var defaultContextSystemPrompt = ({ context = "" }) => {
  return `Context information is below.
---------------------
${context}
---------------------`;
};
var defaultKeywordExtractPrompt = ({
  context = "",
  maxKeywords = 10
}) => {
  return `
Some text is provided below. Given the text, extract up to ${maxKeywords} keywords from the text. Avoid stopwords.
---------------------
${context}
---------------------
Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'
`;
};
var defaultQueryKeywordExtractPrompt = ({
  question = "",
  maxKeywords = 10
}) => {
  return `(
  "A question is provided below. Given the question, extract up to ${maxKeywords} "
  "keywords from the text. Focus on extracting the keywords that we can use "
  "to best lookup answers to the question. Avoid stopwords."
  "---------------------"
  "${question}"
  "---------------------"
  "Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'"
)`;
};

// src/Response.ts
var Response = class {
  constructor(response, sourceNodes) {
    this.response = response;
    this.sourceNodes = sourceNodes || [];
  }
  getFormattedSources() {
    throw new Error("Not implemented yet");
  }
  toString() {
    var _a;
    return (_a = this.response) != null ? _a : "";
  }
};

// src/constants.ts
var DEFAULT_CONTEXT_WINDOW = 3900;
var DEFAULT_NUM_OUTPUTS = 256;
var DEFAULT_CHUNK_SIZE = 1024;
var DEFAULT_CHUNK_OVERLAP = 20;
var DEFAULT_CHUNK_OVERLAP_RATIO = 0.1;
var DEFAULT_SIMILARITY_TOP_K = 2;
var DEFAULT_EMBEDDING_DIM = 1536;
var DEFAULT_PADDING = 5;

// src/storage/vectorStore/types.ts
var VectorStoreQueryMode = /* @__PURE__ */ ((VectorStoreQueryMode2) => {
  VectorStoreQueryMode2["DEFAULT"] = "default";
  VectorStoreQueryMode2["SPARSE"] = "sparse";
  VectorStoreQueryMode2["HYBRID"] = "hybrid";
  VectorStoreQueryMode2["SVM"] = "svm";
  VectorStoreQueryMode2["LOGISTIC_REGRESSION"] = "logistic_regression";
  VectorStoreQueryMode2["LINEAR_REGRESSION"] = "linear_regression";
  VectorStoreQueryMode2["MMR"] = "mmr";
  return VectorStoreQueryMode2;
})(VectorStoreQueryMode || {});

// src/Embedding.ts
var SimilarityType = /* @__PURE__ */ ((SimilarityType2) => {
  SimilarityType2["DEFAULT"] = "cosine";
  SimilarityType2["DOT_PRODUCT"] = "dot_product";
  SimilarityType2["EUCLIDEAN"] = "euclidean";
  return SimilarityType2;
})(SimilarityType || {});
function similarity(embedding1, embedding2, mode = "cosine" /* DEFAULT */) {
  if (embedding1.length !== embedding2.length) {
    throw new Error("Embedding length mismatch");
  }
  function norm(x) {
    let result = 0;
    for (let i = 0; i < x.length; i++) {
      result += x[i] * x[i];
    }
    return Math.sqrt(result);
  }
  switch (mode) {
    case "euclidean" /* EUCLIDEAN */: {
      let difference = embedding1.map((x, i) => x - embedding2[i]);
      return -norm(difference);
    }
    case "dot_product" /* DOT_PRODUCT */: {
      let result = 0;
      for (let i = 0; i < embedding1.length; i++) {
        result += embedding1[i] * embedding2[i];
      }
      return result;
    }
    case "cosine" /* DEFAULT */: {
      return similarity(embedding1, embedding2, "dot_product" /* DOT_PRODUCT */) / (norm(embedding1) * norm(embedding2));
    }
    default:
      throw new Error("Not implemented yet");
  }
}
function getTopKEmbeddings(queryEmbedding, embeddings, similarityTopK = DEFAULT_SIMILARITY_TOP_K, embeddingIds = null, similarityCutoff = null) {
  if (embeddingIds == null) {
    embeddingIds = Array(embeddings.length).map((_14, i) => i);
  }
  if (embeddingIds.length !== embeddings.length) {
    throw new Error(
      "getTopKEmbeddings: embeddings and embeddingIds length mismatch"
    );
  }
  let similarities = [];
  for (let i = 0; i < embeddings.length; i++) {
    const sim = similarity(queryEmbedding, embeddings[i]);
    if (similarityCutoff == null || sim > similarityCutoff) {
      similarities.push({ similarity: sim, id: embeddingIds[i] });
    }
  }
  similarities.sort((a, b) => b.similarity - a.similarity);
  let resultSimilarities = [];
  let resultIds = [];
  for (let i = 0; i < similarityTopK; i++) {
    if (i >= similarities.length) {
      break;
    }
    resultSimilarities.push(similarities[i].similarity);
    resultIds.push(similarities[i].id);
  }
  return [resultSimilarities, resultIds];
}
function getTopKEmbeddingsLearner(queryEmbedding, embeddings, similarityTopK, embeddingsIds, queryMode = "svm" /* SVM */) {
  throw new Error("Not implemented yet");
}
function getTopKMMREmbeddings(queryEmbedding, embeddings, similarityFn = null, similarityTopK = null, embeddingIds = null, _similarityCutoff = null, mmrThreshold = null) {
  let threshold = mmrThreshold || 0.5;
  similarityFn = similarityFn || similarity;
  if (embeddingIds === null || embeddingIds.length === 0) {
    embeddingIds = Array.from({ length: embeddings.length }, (_14, i) => i);
  }
  let fullEmbedMap = new Map(embeddingIds.map((value, i) => [value, i]));
  let embedMap = new Map(fullEmbedMap);
  let embedSimilarity = /* @__PURE__ */ new Map();
  let score = Number.NEGATIVE_INFINITY;
  let highScoreId = null;
  for (let i = 0; i < embeddings.length; i++) {
    let emb = embeddings[i];
    let similarity2 = similarityFn(queryEmbedding, emb);
    embedSimilarity.set(embeddingIds[i], similarity2);
    if (similarity2 * threshold > score) {
      highScoreId = embeddingIds[i];
      score = similarity2 * threshold;
    }
  }
  let results = [];
  let embeddingLength = embeddings.length;
  let similarityTopKCount = similarityTopK || embeddingLength;
  while (results.length < Math.min(similarityTopKCount, embeddingLength)) {
    results.push([score, highScoreId]);
    embedMap.delete(highScoreId);
    let recentEmbeddingId = highScoreId;
    score = Number.NEGATIVE_INFINITY;
    for (let embedId of Array.from(embedMap.keys())) {
      let overlapWithRecent = similarityFn(
        embeddings[embedMap.get(embedId)],
        embeddings[fullEmbedMap.get(recentEmbeddingId)]
      );
      if (threshold * embedSimilarity.get(embedId) - (1 - threshold) * overlapWithRecent > score) {
        score = threshold * embedSimilarity.get(embedId) - (1 - threshold) * overlapWithRecent;
        highScoreId = embedId;
      }
    }
  }
  let resultSimilarities = results.map(([s, _14]) => s);
  let resultIds = results.map(([_14, n]) => n);
  return [resultSimilarities, resultIds];
}
var BaseEmbedding = class {
  similarity(embedding1, embedding2, mode = "cosine" /* DEFAULT */) {
    return similarity(embedding1, embedding2, mode);
  }
};
var OpenAIEmbedding = class extends BaseEmbedding {
  constructor(init) {
    var _a, _b, _c, _d, _e;
    super();
    // OpenAI session params
    this.apiKey = void 0;
    this.model = "text-embedding-ada-002" /* TEXT_EMBED_ADA_002 */;
    this.maxRetries = (_a = init == null ? void 0 : init.maxRetries) != null ? _a : 10;
    this.timeout = (_b = init == null ? void 0 : init.timeout) != null ? _b : 60 * 1e3;
    this.additionalSessionOptions = init == null ? void 0 : init.additionalSessionOptions;
    if ((init == null ? void 0 : init.azure) || shouldUseAzure()) {
      const azureConfig = getAzureConfigFromEnv(__spreadProps(__spreadValues({}, init == null ? void 0 : init.azure), {
        model: getAzureModel(this.model)
      }));
      if (!azureConfig.apiKey) {
        throw new Error(
          "Azure API key is required for OpenAI Azure models. Please set the AZURE_OPENAI_KEY environment variable."
        );
      }
      this.apiKey = azureConfig.apiKey;
      this.session = (_c = init == null ? void 0 : init.session) != null ? _c : getOpenAISession(__spreadValues({
        azure: true,
        apiKey: this.apiKey,
        baseURL: getAzureBaseUrl(azureConfig),
        maxRetries: this.maxRetries,
        timeout: this.timeout,
        defaultQuery: { "api-version": azureConfig.apiVersion }
      }, this.additionalSessionOptions));
    } else {
      this.apiKey = (_d = init == null ? void 0 : init.apiKey) != null ? _d : void 0;
      this.session = (_e = init == null ? void 0 : init.session) != null ? _e : getOpenAISession(__spreadValues({
        apiKey: this.apiKey,
        maxRetries: this.maxRetries,
        timeout: this.timeout
      }, this.additionalSessionOptions));
    }
  }
  getOpenAIEmbedding(input) {
    return __async(this, null, function* () {
      const { data } = yield this.session.openai.embeddings.create({
        model: this.model,
        input
      });
      return data[0].embedding;
    });
  }
  getTextEmbedding(text) {
    return __async(this, null, function* () {
      return this.getOpenAIEmbedding(text);
    });
  }
  getQueryEmbedding(query) {
    return __async(this, null, function* () {
      return this.getOpenAIEmbedding(query);
    });
  }
};

// src/Node.ts
import crypto from "crypto";
import { v4 as uuidv42 } from "uuid";
var NodeRelationship = /* @__PURE__ */ ((NodeRelationship2) => {
  NodeRelationship2["SOURCE"] = "SOURCE";
  NodeRelationship2["PREVIOUS"] = "PREVIOUS";
  NodeRelationship2["NEXT"] = "NEXT";
  NodeRelationship2["PARENT"] = "PARENT";
  NodeRelationship2["CHILD"] = "CHILD";
  return NodeRelationship2;
})(NodeRelationship || {});
var ObjectType = /* @__PURE__ */ ((ObjectType2) => {
  ObjectType2["TEXT"] = "TEXT";
  ObjectType2["IMAGE"] = "IMAGE";
  ObjectType2["INDEX"] = "INDEX";
  ObjectType2["DOCUMENT"] = "DOCUMENT";
  return ObjectType2;
})(ObjectType || {});
var MetadataMode = /* @__PURE__ */ ((MetadataMode2) => {
  MetadataMode2["ALL"] = "ALL";
  MetadataMode2["EMBED"] = "EMBED";
  MetadataMode2["LLM"] = "LLM";
  MetadataMode2["NONE"] = "NONE";
  return MetadataMode2;
})(MetadataMode || {});
var BaseNode = class {
  constructor(init) {
    /**
     * The unique ID of the Node/Document. The trailing underscore is here
     * to avoid collisions with the id keyword in Python.
     *
     * Set to a UUID by default.
     */
    this.id_ = uuidv42();
    // Metadata fields
    this.metadata = {};
    this.excludedEmbedMetadataKeys = [];
    this.excludedLlmMetadataKeys = [];
    this.relationships = {};
    this.hash = "";
    Object.assign(this, init);
  }
  get sourceNode() {
    const relationship = this.relationships["SOURCE" /* SOURCE */];
    if (Array.isArray(relationship)) {
      throw new Error("Source object must be a single RelatedNodeInfo object");
    }
    return relationship;
  }
  get prevNode() {
    const relationship = this.relationships["PREVIOUS" /* PREVIOUS */];
    if (Array.isArray(relationship)) {
      throw new Error(
        "Previous object must be a single RelatedNodeInfo object"
      );
    }
    return relationship;
  }
  get nextNode() {
    const relationship = this.relationships["NEXT" /* NEXT */];
    if (Array.isArray(relationship)) {
      throw new Error("Next object must be a single RelatedNodeInfo object");
    }
    return relationship;
  }
  get parentNode() {
    const relationship = this.relationships["PARENT" /* PARENT */];
    if (Array.isArray(relationship)) {
      throw new Error("Parent object must be a single RelatedNodeInfo object");
    }
    return relationship;
  }
  get childNodes() {
    const relationship = this.relationships["CHILD" /* CHILD */];
    if (!Array.isArray(relationship)) {
      throw new Error(
        "Child object must be a an array of RelatedNodeInfo objects"
      );
    }
    return relationship;
  }
  getEmbedding() {
    if (this.embedding === void 0) {
      throw new Error("Embedding not set");
    }
    return this.embedding;
  }
  asRelatedNodeInfo() {
    return {
      nodeId: this.id_,
      metadata: this.metadata,
      hash: this.hash
    };
  }
  /**
   * Used with built in JSON.stringify
   * @returns
   */
  toJSON() {
    return __spreadProps(__spreadValues({}, this), { type: this.getType() });
  }
};
var TextNode = class _TextNode extends BaseNode {
  constructor(init) {
    super(init);
    this.text = "";
    // textTemplate: NOTE write your own formatter if needed
    // metadataTemplate: NOTE write your own formatter if needed
    this.metadataSeparator = "\n";
    Object.assign(this, init);
    if (new.target === _TextNode) {
      this.hash = this.generateHash();
    }
  }
  /**
   * Generate a hash of the text node.
   * The ID is not part of the hash as it can change independent of content.
   * @returns
   */
  generateHash() {
    const hashFunction = crypto.createHash("sha256");
    hashFunction.update(`type=${this.getType()}`);
    hashFunction.update(
      `startCharIdx=${this.startCharIdx} endCharIdx=${this.endCharIdx}`
    );
    hashFunction.update(this.getContent("ALL" /* ALL */));
    return hashFunction.digest("base64");
  }
  getType() {
    return "TEXT" /* TEXT */;
  }
  getContent(metadataMode = "NONE" /* NONE */) {
    const metadataStr = this.getMetadataStr(metadataMode).trim();
    return `${metadataStr}

${this.text}`.trim();
  }
  getMetadataStr(metadataMode) {
    if (metadataMode === "NONE" /* NONE */) {
      return "";
    }
    const usableMetadataKeys = new Set(Object.keys(this.metadata).sort());
    if (metadataMode === "LLM" /* LLM */) {
      for (const key of this.excludedLlmMetadataKeys) {
        usableMetadataKeys.delete(key);
      }
    } else if (metadataMode === "EMBED" /* EMBED */) {
      for (const key of this.excludedEmbedMetadataKeys) {
        usableMetadataKeys.delete(key);
      }
    }
    return [...usableMetadataKeys].map((key) => `${key}: ${this.metadata[key]}`).join(this.metadataSeparator);
  }
  setContent(value) {
    this.text = value;
    this.hash = this.generateHash();
  }
  getNodeInfo() {
    return { start: this.startCharIdx, end: this.endCharIdx };
  }
  getText() {
    return this.getContent("NONE" /* NONE */);
  }
};
var IndexNode = class _IndexNode extends TextNode {
  constructor(init) {
    super(init);
    this.indexId = "";
    Object.assign(this, init);
    if (new.target === _IndexNode) {
      this.hash = this.generateHash();
    }
  }
  getType() {
    return "INDEX" /* INDEX */;
  }
};
var Document = class _Document extends TextNode {
  constructor(init) {
    super(init);
    Object.assign(this, init);
    if (new.target === _Document) {
      this.hash = this.generateHash();
    }
  }
  getType() {
    return "DOCUMENT" /* DOCUMENT */;
  }
};
function jsonToNode(json) {
  if (!json.type) {
    throw new Error("Node type not found");
  }
  switch (json.type) {
    case "TEXT" /* TEXT */:
      return new TextNode(json);
    case "INDEX" /* INDEX */:
      return new IndexNode(json);
    case "DOCUMENT" /* DOCUMENT */:
      return new Document(json);
    default:
      throw new Error(`Invalid node type: ${json.type}`);
  }
}

// src/TextSplitter.ts
var TextSplit = class {
  constructor(textChunk, numCharOverlap = void 0) {
    this.textChunk = textChunk;
    this.numCharOverlap = numCharOverlap;
  }
};
var englishSentenceTokenizer = (text) => {
  return text.match(/.+?[.?!]+[\])'"`’”]*(?:\s|$)|.+/g);
};
var cjkSentenceTokenizer = (text) => {
  return text.match(
    /.+?[.?!]+[\])'"`’”]*(?:\s|$)|.+?[。？！]+[\])'"`’”]*(?:\s|$)?|.+/g
  );
};
var unixLineSeparator = "\n";
var windowsLineSeparator = "\r\n";
var unixParagraphSeparator = unixLineSeparator + unixLineSeparator;
var windowsParagraphSeparator = windowsLineSeparator + windowsLineSeparator;
var SentenceSplitter = class {
  constructor(options) {
    const {
      chunkSize = DEFAULT_CHUNK_SIZE,
      chunkOverlap = DEFAULT_CHUNK_OVERLAP,
      tokenizer = null,
      tokenizerDecoder = null,
      paragraphSeparator = unixParagraphSeparator,
      chunkingTokenizerFn = void 0,
      splitLongSentences = false
    } = options != null ? options : {};
    if (chunkOverlap > chunkSize) {
      throw new Error(
        `Got a larger chunk overlap (${chunkOverlap}) than chunk size (${chunkSize}), should be smaller.`
      );
    }
    this.chunkSize = chunkSize;
    this.chunkOverlap = chunkOverlap;
    this.tokenizer = tokenizer != null ? tokenizer : globalsHelper.tokenizer();
    this.tokenizerDecoder = tokenizerDecoder != null ? tokenizerDecoder : globalsHelper.tokenizerDecoder();
    this.paragraphSeparator = paragraphSeparator;
    this.chunkingTokenizerFn = chunkingTokenizerFn != null ? chunkingTokenizerFn : englishSentenceTokenizer;
    this.splitLongSentences = splitLongSentences;
  }
  getEffectiveChunkSize(extraInfoStr) {
    let effectiveChunkSize;
    if (extraInfoStr != void 0) {
      const numExtraTokens = this.tokenizer(`${extraInfoStr}

`).length + 1;
      effectiveChunkSize = this.chunkSize - numExtraTokens;
      if (effectiveChunkSize <= 0) {
        throw new Error(
          "Effective chunk size is non positive after considering extra_info"
        );
      }
    } else {
      effectiveChunkSize = this.chunkSize;
    }
    return effectiveChunkSize;
  }
  getParagraphSplits(text, effectiveChunkSize) {
    let paragraphSplits = text.split(this.paragraphSeparator);
    let idx = 0;
    if (effectiveChunkSize == void 0) {
      return paragraphSplits;
    }
    while (idx < paragraphSplits.length) {
      if (idx < paragraphSplits.length - 1 && paragraphSplits[idx].length < effectiveChunkSize) {
        paragraphSplits[idx] = [
          paragraphSplits[idx],
          paragraphSplits[idx + 1]
        ].join(this.paragraphSeparator);
        paragraphSplits.splice(idx + 1, 1);
      } else {
        idx += 1;
      }
    }
    return paragraphSplits;
  }
  getSentenceSplits(text, effectiveChunkSize) {
    let paragraphSplits = this.getParagraphSplits(text, effectiveChunkSize);
    let splits = [];
    for (const parText of paragraphSplits) {
      const sentenceSplits = this.chunkingTokenizerFn(parText);
      if (!sentenceSplits) {
        continue;
      }
      for (const sentence_split of sentenceSplits) {
        splits.push(sentence_split.trim());
      }
    }
    return splits;
  }
  /**
   * Splits sentences into chunks if necessary.
   *
   * This isn't great behavior because it can split down the middle of a
   * word or in non-English split down the middle of a Unicode codepoint
   * so the splitting is turned off by default. If you need it, please
   * set the splitLongSentences option to true.
   * @param sentenceSplits
   * @param effectiveChunkSize
   * @returns
   */
  processSentenceSplits(sentenceSplits, effectiveChunkSize) {
    if (!this.splitLongSentences) {
      return sentenceSplits.map((split) => ({
        text: split,
        numTokens: this.tokenizer(split).length
      }));
    }
    let newSplits = [];
    for (const split of sentenceSplits) {
      let splitTokens = this.tokenizer(split);
      const splitLen = splitTokens.length;
      if (splitLen <= effectiveChunkSize) {
        newSplits.push({ text: split, numTokens: splitLen });
      } else {
        for (let i = 0; i < splitLen; i += effectiveChunkSize) {
          const cur_split = this.tokenizerDecoder(
            splitTokens.slice(i, i + effectiveChunkSize)
          );
          newSplits.push({ text: cur_split, numTokens: effectiveChunkSize });
        }
      }
    }
    return newSplits;
  }
  combineTextSplits(newSentenceSplits, effectiveChunkSize) {
    let docs = [];
    let curChunkSentences = [];
    let curChunkTokens = 0;
    for (let i = 0; i < newSentenceSplits.length; i++) {
      if (curChunkTokens + newSentenceSplits[i].numTokens > effectiveChunkSize) {
        docs.push(
          new TextSplit(
            curChunkSentences.map((sentence) => sentence.text).join(" ").trim()
          )
        );
        const lastChunkSentences = curChunkSentences;
        curChunkTokens = 0;
        curChunkSentences = [];
        for (let j = lastChunkSentences.length - 1; j >= 0; j--) {
          if (curChunkTokens + lastChunkSentences[j].numTokens > this.chunkOverlap) {
            break;
          }
          curChunkSentences.unshift(lastChunkSentences[j]);
          curChunkTokens += lastChunkSentences[j].numTokens + 1;
        }
      }
      curChunkSentences.push(newSentenceSplits[i]);
      curChunkTokens += newSentenceSplits[i].numTokens + 1;
    }
    docs.push(
      new TextSplit(
        curChunkSentences.map((sentence) => sentence.text).join(" ").trim()
      )
    );
    return docs;
  }
  splitTextWithOverlaps(text, extraInfoStr) {
    if (text == "") {
      return [];
    }
    let effectiveChunkSize = this.getEffectiveChunkSize(extraInfoStr);
    let sentenceSplits = this.getSentenceSplits(text, effectiveChunkSize);
    let newSentenceSplits = this.processSentenceSplits(
      sentenceSplits,
      effectiveChunkSize
    );
    let combinedTextSplits = this.combineTextSplits(
      newSentenceSplits,
      effectiveChunkSize
    );
    return combinedTextSplits;
  }
  splitText(text, extraInfoStr) {
    const text_splits = this.splitTextWithOverlaps(text);
    const chunks = text_splits.map((text_split) => text_split.textChunk);
    return chunks;
  }
};

// src/NodeParser.ts
function getTextSplitsFromDocument(document, textSplitter) {
  const text = document.getText();
  const splits = textSplitter.splitText(text);
  return splits;
}
function getNodesFromDocument(document, textSplitter, includeMetadata = true, includePrevNextRel = true) {
  let nodes = [];
  const textSplits = getTextSplitsFromDocument(document, textSplitter);
  textSplits.forEach((textSplit) => {
    const node = new TextNode({
      text: textSplit,
      metadata: includeMetadata ? document.metadata : {}
    });
    node.relationships["SOURCE" /* SOURCE */] = document.asRelatedNodeInfo();
    nodes.push(node);
  });
  if (includePrevNextRel) {
    nodes.forEach((node, index) => {
      if (index > 0) {
        node.relationships["PREVIOUS" /* PREVIOUS */] = nodes[index - 1].asRelatedNodeInfo();
      }
      if (index < nodes.length - 1) {
        node.relationships["NEXT" /* NEXT */] = nodes[index + 1].asRelatedNodeInfo();
      }
    });
  }
  return nodes;
}
var SimpleNodeParser = class _SimpleNodeParser {
  constructor(init) {
    var _a, _b, _c, _d, _e;
    this.textSplitter = (_c = init == null ? void 0 : init.textSplitter) != null ? _c : new SentenceSplitter({
      chunkSize: (_a = init == null ? void 0 : init.chunkSize) != null ? _a : DEFAULT_CHUNK_SIZE,
      chunkOverlap: (_b = init == null ? void 0 : init.chunkOverlap) != null ? _b : DEFAULT_CHUNK_OVERLAP
    });
    this.includeMetadata = (_d = init == null ? void 0 : init.includeMetadata) != null ? _d : true;
    this.includePrevNextRel = (_e = init == null ? void 0 : init.includePrevNextRel) != null ? _e : true;
  }
  static fromDefaults(init) {
    return new _SimpleNodeParser(init);
  }
  /**
   * Generate Node objects from documents
   * @param documents
   */
  getNodesFromDocuments(documents) {
    return documents.map((document) => getNodesFromDocument(document, this.textSplitter)).flat();
  }
};

// src/PromptHelper.ts
function getEmptyPromptTxt(prompt) {
  return prompt({});
}
function getBiggestPrompt(prompts) {
  const emptyPromptTexts = prompts.map(getEmptyPromptTxt);
  const emptyPromptLengths = emptyPromptTexts.map((text) => text.length);
  const maxEmptyPromptLength = Math.max(...emptyPromptLengths);
  const maxEmptyPromptIndex = emptyPromptLengths.indexOf(maxEmptyPromptLength);
  return prompts[maxEmptyPromptIndex];
}
var PromptHelper = class {
  constructor(contextWindow = DEFAULT_CONTEXT_WINDOW, numOutput = DEFAULT_NUM_OUTPUTS, chunkOverlapRatio = DEFAULT_CHUNK_OVERLAP_RATIO, chunkSizeLimit, tokenizer, separator = " ") {
    this.contextWindow = DEFAULT_CONTEXT_WINDOW;
    this.numOutput = DEFAULT_NUM_OUTPUTS;
    this.chunkOverlapRatio = DEFAULT_CHUNK_OVERLAP_RATIO;
    this.separator = " ";
    this.contextWindow = contextWindow;
    this.numOutput = numOutput;
    this.chunkOverlapRatio = chunkOverlapRatio;
    this.chunkSizeLimit = chunkSizeLimit;
    this.tokenizer = tokenizer || globalsHelper.tokenizer();
    this.separator = separator;
  }
  /**
   * Given a prompt, return the maximum size of the inputs to the prompt.
   * @param prompt
   * @returns
   */
  getAvailableContextSize(prompt) {
    const emptyPromptText = getEmptyPromptTxt(prompt);
    const promptTokens = this.tokenizer(emptyPromptText);
    const numPromptTokens = promptTokens.length;
    return this.contextWindow - numPromptTokens - this.numOutput;
  }
  /**
   * Find the maximum size of each chunk given a prompt.
   * @param prompt
   * @param numChunks
   * @param padding
   * @returns
   */
  getAvailableChunkSize(prompt, numChunks = 1, padding = 5) {
    const availableContextSize = this.getAvailableContextSize(prompt);
    const result = Math.floor(availableContextSize / numChunks) - padding;
    if (this.chunkSizeLimit) {
      return Math.min(this.chunkSizeLimit, result);
    } else {
      return result;
    }
  }
  /**
   * Creates a text splitter with the correct chunk sizes and overlaps given a prompt.
   * @param prompt
   * @param numChunks
   * @param padding
   * @returns
   */
  getTextSplitterGivenPrompt(prompt, numChunks = 1, padding = DEFAULT_PADDING) {
    const chunkSize = this.getAvailableChunkSize(prompt, numChunks, padding);
    if (chunkSize === 0) {
      throw new Error("Got 0 as available chunk size");
    }
    const chunkOverlap = this.chunkOverlapRatio * chunkSize;
    const textSplitter = new SentenceSplitter({ chunkSize, chunkOverlap });
    return textSplitter;
  }
  /**
   * Repack resplits the strings based on the optimal text splitter.
   * @param prompt
   * @param textChunks
   * @param padding
   * @returns
   */
  repack(prompt, textChunks, padding = DEFAULT_PADDING) {
    const textSplitter = this.getTextSplitterGivenPrompt(prompt, 1, padding);
    const combinedStr = textChunks.join("\n\n");
    return textSplitter.splitText(combinedStr);
  }
};

// src/ServiceContext.ts
function serviceContextFromDefaults(options) {
  var _a, _b, _c, _d, _e;
  const callbackManager = (_a = options == null ? void 0 : options.callbackManager) != null ? _a : new CallbackManager();
  const serviceContext = {
    llm: (_b = options == null ? void 0 : options.llm) != null ? _b : new OpenAI2(),
    embedModel: (_c = options == null ? void 0 : options.embedModel) != null ? _c : new OpenAIEmbedding(),
    nodeParser: (_d = options == null ? void 0 : options.nodeParser) != null ? _d : new SimpleNodeParser({
      chunkSize: options == null ? void 0 : options.chunkSize,
      chunkOverlap: options == null ? void 0 : options.chunkOverlap
    }),
    promptHelper: (_e = options == null ? void 0 : options.promptHelper) != null ? _e : new PromptHelper(),
    callbackManager
  };
  return serviceContext;
}
function serviceContextFromServiceContext(serviceContext, options) {
  const newServiceContext = __spreadValues({}, serviceContext);
  if (options.llm) {
    newServiceContext.llm = options.llm;
  }
  if (options.promptHelper) {
    newServiceContext.promptHelper = options.promptHelper;
  }
  if (options.embedModel) {
    newServiceContext.embedModel = options.embedModel;
  }
  if (options.nodeParser) {
    newServiceContext.nodeParser = options.nodeParser;
  }
  if (options.callbackManager) {
    newServiceContext.callbackManager = options.callbackManager;
  }
  return newServiceContext;
}

// src/ChatEngine.ts
var SimpleChatEngine = class {
  constructor(init) {
    var _a, _b;
    this.chatHistory = (_a = init == null ? void 0 : init.chatHistory) != null ? _a : [];
    this.llm = (_b = init == null ? void 0 : init.llm) != null ? _b : new OpenAI2();
  }
  chat(message, chatHistory, streaming) {
    return __async(this, null, function* () {
      if (streaming) {
        return this.streamChat(message, chatHistory);
      }
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      chatHistory.push({ content: message, role: "user" });
      const response = yield this.llm.chat(chatHistory, void 0);
      chatHistory.push(response.message);
      this.chatHistory = chatHistory;
      return new Response(response.message.content);
    });
  }
  streamChat(message, chatHistory) {
    return __asyncGenerator(this, null, function* () {
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      chatHistory.push({ content: message, role: "user" });
      const response_generator = yield new __await(this.llm.chat(
        chatHistory,
        void 0,
        true
      ));
      var accumulator = "";
      try {
        for (var iter = __forAwait(response_generator), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          accumulator += part;
          yield part;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      chatHistory.push({ content: accumulator, role: "assistant" });
      this.chatHistory = chatHistory;
      return;
    });
  }
  reset() {
    this.chatHistory = [];
  }
};
var CondenseQuestionChatEngine = class {
  constructor(init) {
    var _a, _b, _c;
    this.queryEngine = init.queryEngine;
    this.chatHistory = (_a = init == null ? void 0 : init.chatHistory) != null ? _a : [];
    this.serviceContext = (_b = init == null ? void 0 : init.serviceContext) != null ? _b : serviceContextFromDefaults({});
    this.condenseMessagePrompt = (_c = init == null ? void 0 : init.condenseMessagePrompt) != null ? _c : defaultCondenseQuestionPrompt;
  }
  condenseQuestion(chatHistory, question) {
    return __async(this, null, function* () {
      const chatHistoryStr = messagesToHistoryStr(chatHistory);
      return this.serviceContext.llm.complete(
        defaultCondenseQuestionPrompt({
          question,
          chatHistory: chatHistoryStr
        })
      );
    });
  }
  chat(message, chatHistory, streaming) {
    return __async(this, null, function* () {
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      const condensedQuestion = (yield this.condenseQuestion(chatHistory, message)).message.content;
      const response = yield this.queryEngine.query(condensedQuestion);
      chatHistory.push({ content: message, role: "user" });
      chatHistory.push({ content: response.response, role: "assistant" });
      return response;
    });
  }
  reset() {
    this.chatHistory = [];
  }
};
var DefaultContextGenerator = class {
  constructor(init) {
    var _a;
    this.retriever = init.retriever;
    this.contextSystemPrompt = (_a = init == null ? void 0 : init.contextSystemPrompt) != null ? _a : defaultContextSystemPrompt;
    this.nodePostprocessors = init.nodePostprocessors || [];
  }
  applyNodePostprocessors(nodes) {
    return this.nodePostprocessors.reduce(
      (nodes2, nodePostprocessor) => nodePostprocessor.postprocessNodes(nodes2),
      nodes
    );
  }
  generate(message, parentEvent) {
    return __async(this, null, function* () {
      if (!parentEvent) {
        parentEvent = {
          id: uuidv43(),
          type: "wrapper",
          tags: ["final"]
        };
      }
      const sourceNodesWithScore = yield this.retriever.retrieve(
        message,
        parentEvent
      );
      const nodes = this.applyNodePostprocessors(sourceNodesWithScore);
      return {
        message: {
          content: this.contextSystemPrompt({
            context: nodes.map((r) => r.node.text).join("\n\n")
          }),
          role: "system"
        },
        nodes
      };
    });
  }
};
var ContextChatEngine = class {
  constructor(init) {
    var _a, _b;
    this.chatModel = (_a = init.chatModel) != null ? _a : new OpenAI2({ model: "gpt-3.5-turbo-16k" });
    this.chatHistory = (_b = init == null ? void 0 : init.chatHistory) != null ? _b : [];
    this.contextGenerator = new DefaultContextGenerator({
      retriever: init.retriever,
      contextSystemPrompt: init == null ? void 0 : init.contextSystemPrompt
    });
  }
  chat(message, chatHistory, streaming) {
    return __async(this, null, function* () {
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      if (streaming) {
        return this.streamChat(message, chatHistory);
      }
      const parentEvent = {
        id: uuidv43(),
        type: "wrapper",
        tags: ["final"]
      };
      const context = yield this.contextGenerator.generate(message, parentEvent);
      chatHistory.push({ content: message, role: "user" });
      const response = yield this.chatModel.chat(
        [context.message, ...chatHistory],
        parentEvent
      );
      chatHistory.push(response.message);
      this.chatHistory = chatHistory;
      return new Response(
        response.message.content,
        context.nodes.map((r) => r.node)
      );
    });
  }
  streamChat(message, chatHistory) {
    return __asyncGenerator(this, null, function* () {
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      const parentEvent = {
        id: uuidv43(),
        type: "wrapper",
        tags: ["final"]
      };
      const context = yield new __await(this.contextGenerator.generate(message, parentEvent));
      chatHistory.push({ content: message, role: "user" });
      const response_stream = yield new __await(this.chatModel.chat(
        [context.message, ...chatHistory],
        parentEvent,
        true
      ));
      var accumulator = "";
      try {
        for (var iter = __forAwait(response_stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          accumulator += part;
          yield part;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      chatHistory.push({ content: accumulator, role: "assistant" });
      this.chatHistory = chatHistory;
      return;
    });
  }
  reset() {
    this.chatHistory = [];
  }
};
var HistoryChatEngine = class {
  constructor(init) {
    var _a;
    this.llm = (_a = init == null ? void 0 : init.llm) != null ? _a : new OpenAI2();
    this.contextGenerator = init == null ? void 0 : init.contextGenerator;
  }
  chat(message, chatHistory, streaming) {
    return __async(this, null, function* () {
      var _a;
      if (streaming) {
        return this.streamChat(message, chatHistory);
      }
      const context = yield (_a = this.contextGenerator) == null ? void 0 : _a.generate(message);
      chatHistory.addMessage({
        content: message,
        role: "user"
      });
      const response = yield this.llm.chat(
        yield chatHistory.requestMessages(
          context ? [context.message] : void 0
        )
      );
      chatHistory.addMessage(response.message);
      return new Response(response.message.content);
    });
  }
  streamChat(message, chatHistory) {
    return __asyncGenerator(this, null, function* () {
      var _a;
      const context = yield new __await((_a = this.contextGenerator) == null ? void 0 : _a.generate(message));
      chatHistory.addMessage({
        content: message,
        role: "user"
      });
      const response_stream = yield new __await(this.llm.chat(
        yield new __await(chatHistory.requestMessages(
          context ? [context.message] : void 0
        )),
        void 0,
        true
      ));
      var accumulator = "";
      try {
        for (var iter = __forAwait(response_stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          accumulator += part;
          yield part;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      chatHistory.addMessage({
        content: accumulator,
        role: "assistant"
      });
      return;
    });
  }
};

// src/ChatHistory.ts
var SimpleChatHistory = class {
  constructor(init) {
    var _a;
    this.messages = (_a = init == null ? void 0 : init.messages) != null ? _a : [];
    this.messagesBefore = this.messages.length;
  }
  addMessage(message) {
    this.messages.push(message);
  }
  requestMessages(transientMessages) {
    return __async(this, null, function* () {
      return [...transientMessages != null ? transientMessages : [], ...this.messages];
    });
  }
  reset() {
    this.messages = [];
  }
  newMessages() {
    const newMessages = this.messages.slice(this.messagesBefore);
    this.messagesBefore = this.messages.length;
    return newMessages;
  }
};
var SummaryChatHistory = class {
  constructor(init) {
    var _a, _b, _c;
    this.messages = (_a = init == null ? void 0 : init.messages) != null ? _a : [];
    this.messagesBefore = this.messages.length;
    this.summaryPrompt = (_b = init == null ? void 0 : init.summaryPrompt) != null ? _b : defaultSummaryPrompt;
    this.llm = (_c = init == null ? void 0 : init.llm) != null ? _c : new OpenAI2();
    if (!this.llm.metadata.maxTokens) {
      throw new Error(
        "LLM maxTokens is not set. Needed so the summarizer ensures the context window size of the LLM."
      );
    }
    this.tokensToSummarize = this.llm.metadata.contextWindow - this.llm.metadata.maxTokens;
  }
  summarize() {
    return __async(this, null, function* () {
      const messagesToSummarize = this.calcConversationMessages();
      let promptMessages;
      do {
        promptMessages = [
          {
            content: this.summaryPrompt({
              context: messagesToHistoryStr(messagesToSummarize)
            }),
            role: "user"
          }
        ];
        messagesToSummarize.shift();
      } while (this.llm.tokens(promptMessages) > this.tokensToSummarize);
      const response = yield this.llm.chat(promptMessages);
      return { content: response.message.content, role: "memory" };
    });
  }
  addMessage(message) {
    this.messages.push(message);
  }
  // Find last summary message
  getLastSummaryIndex() {
    const reversedMessages = this.messages.slice().reverse();
    const index = reversedMessages.findIndex(
      (message) => message.role === "memory"
    );
    if (index === -1) {
      return null;
    }
    return this.messages.length - 1 - index;
  }
  get systemMessages() {
    return this.messages.filter((message) => message.role === "system");
  }
  get nonSystemMessages() {
    return this.messages.filter((message) => message.role !== "system");
  }
  /**
   * Calculates the messages that describe the conversation so far.
   * If there's no memory, all non-system messages are used.
   * If there's a memory, uses all messages after the last summary message.
   */
  calcConversationMessages(transformSummary) {
    const lastSummaryIndex = this.getLastSummaryIndex();
    if (!lastSummaryIndex) {
      return this.nonSystemMessages;
    } else {
      const summaryMessage = transformSummary ? {
        content: `Summary of the conversation so far: ${this.messages[lastSummaryIndex].content}`,
        role: "system"
      } : this.messages[lastSummaryIndex];
      return [summaryMessage, ...this.messages.slice(lastSummaryIndex + 1)];
    }
  }
  calcCurrentRequestMessages(transientMessages) {
    return [
      ...this.systemMessages,
      ...transientMessages ? transientMessages : [],
      ...this.calcConversationMessages(true)
    ];
  }
  requestMessages(transientMessages) {
    return __async(this, null, function* () {
      const requestMessages = this.calcCurrentRequestMessages(transientMessages);
      const tokens = this.llm.tokens(requestMessages);
      if (tokens > this.tokensToSummarize) {
        const memoryMessage = yield this.summarize();
        const lastMessage = this.messages.at(-1);
        if (lastMessage && lastMessage.role === "user") {
          this.messages.pop();
          this.messages.push(memoryMessage);
          this.messages.push(lastMessage);
        } else {
          this.messages.push(memoryMessage);
        }
        return this.calcCurrentRequestMessages(transientMessages);
      }
      return requestMessages;
    });
  }
  reset() {
    this.messages = [];
  }
  newMessages() {
    const newMessages = this.messages.slice(this.messagesBefore);
    this.messagesBefore = this.messages.length;
    return newMessages;
  }
};

// src/indices/BaseIndex.ts
import { v4 as uuidv44 } from "uuid";
var IndexStruct = class {
  constructor(indexId = uuidv44(), summary = void 0) {
    this.indexId = indexId;
    this.summary = summary;
  }
  toJson() {
    return {
      indexId: this.indexId,
      summary: this.summary
    };
  }
  getSummary() {
    if (this.summary === void 0) {
      throw new Error("summary field of the index dict is not set");
    }
    return this.summary;
  }
};
var IndexStructType = /* @__PURE__ */ ((IndexStructType2) => {
  IndexStructType2["SIMPLE_DICT"] = "simple_dict";
  IndexStructType2["LIST"] = "list";
  IndexStructType2["KEYWORD_TABLE"] = "keyword_table";
  return IndexStructType2;
})(IndexStructType || {});
var IndexDict = class extends IndexStruct {
  constructor() {
    super(...arguments);
    this.nodesDict = {};
    this.type = "simple_dict" /* SIMPLE_DICT */;
  }
  getSummary() {
    if (this.summary === void 0) {
      throw new Error("summary field of the index dict is not set");
    }
    return this.summary;
  }
  addNode(node, textId) {
    const vectorId = textId != null ? textId : node.id_;
    this.nodesDict[vectorId] = node;
  }
  toJson() {
    return __spreadProps(__spreadValues({}, super.toJson()), {
      nodesDict: this.nodesDict,
      type: this.type
    });
  }
  delete(nodeId) {
    delete this.nodesDict[nodeId];
  }
};
function jsonToIndexStruct(json) {
  if (json.type === "list" /* LIST */) {
    const indexList = new IndexList(json.indexId, json.summary);
    indexList.nodes = json.nodes;
    return indexList;
  } else if (json.type === "simple_dict" /* SIMPLE_DICT */) {
    const indexDict = new IndexDict(json.indexId, json.summary);
    indexDict.nodesDict = Object.entries(json.nodesDict).reduce((acc, [key, value]) => {
      acc[key] = jsonToNode(value);
      return acc;
    }, {});
    return indexDict;
  } else {
    throw new Error(`Unknown index struct type: ${json.type}`);
  }
}
var IndexList = class extends IndexStruct {
  constructor() {
    super(...arguments);
    this.nodes = [];
    this.type = "list" /* LIST */;
  }
  addNode(node) {
    this.nodes.push(node.id_);
  }
  toJson() {
    return __spreadProps(__spreadValues({}, super.toJson()), {
      nodes: this.nodes,
      type: this.type
    });
  }
};
var KeywordTable = class extends IndexStruct {
  constructor() {
    super(...arguments);
    this.table = /* @__PURE__ */ new Map();
    this.type = "keyword_table" /* KEYWORD_TABLE */;
  }
  addNode(keywords, nodeId) {
    keywords.forEach((keyword) => {
      if (!this.table.has(keyword)) {
        this.table.set(keyword, /* @__PURE__ */ new Set());
      }
      this.table.get(keyword).add(nodeId);
    });
  }
  deleteNode(keywords, nodeId) {
    keywords.forEach((keyword) => {
      if (this.table.has(keyword)) {
        this.table.get(keyword).delete(nodeId);
      }
    });
  }
  toJson() {
    return __spreadProps(__spreadValues({}, super.toJson()), {
      table: this.table,
      type: this.type
    });
  }
};
var BaseIndex = class {
  constructor(init) {
    this.serviceContext = init.serviceContext;
    this.storageContext = init.storageContext;
    this.docStore = init.docStore;
    this.vectorStore = init.vectorStore;
    this.indexStore = init.indexStore;
    this.indexStruct = init.indexStruct;
  }
  /**
   * Insert a document into the index.
   * @param document
   */
  insert(document) {
    return __async(this, null, function* () {
      const nodes = this.serviceContext.nodeParser.getNodesFromDocuments([
        document
      ]);
      yield this.insertNodes(nodes);
      this.docStore.setDocumentHash(document.id_, document.hash);
    });
  }
};

// src/indices/BaseNodePostprocessor.ts
var SimilarityPostprocessor = class {
  constructor(options) {
    this.similarityCutoff = options == null ? void 0 : options.similarityCutoff;
  }
  postprocessNodes(nodes) {
    if (this.similarityCutoff === void 0)
      return nodes;
    const cutoff = this.similarityCutoff || 0;
    return nodes.filter((node) => node.score && node.score >= cutoff);
  }
};

// src/QueryEngine.ts
import { v4 as uuidv45 } from "uuid";

// src/OutputParser.ts
var OutputParserError = class _OutputParserError extends Error {
  constructor(message, options = {}) {
    super(message, options);
    this.name = "OutputParserError";
    if (!this.cause) {
      this.cause = options.cause;
    }
    this.output = options.output;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, _OutputParserError);
    }
  }
};
function parseJsonMarkdown(text) {
  text = text.trim();
  const left_square = text.indexOf("[");
  const left_brace = text.indexOf("{");
  var left;
  var right;
  if (left_square < left_brace && left_square != -1) {
    left = left_square;
    right = text.lastIndexOf("]");
  } else {
    left = left_brace;
    right = text.lastIndexOf("}");
  }
  const jsonText = text.substring(left, right + 1);
  try {
    if (left_square === -1) {
      return [JSON.parse(jsonText)];
    }
    return JSON.parse(jsonText);
  } catch (e) {
    throw new OutputParserError("Not a json markdown", { output: text });
  }
}
var SubQuestionOutputParser = class {
  parse(output) {
    const parsed = parseJsonMarkdown(output);
    return { rawOutput: output, parsedOutput: parsed };
  }
  format(output) {
    return output;
  }
};

// src/QuestionGenerator.ts
var LLMQuestionGenerator = class {
  constructor(init) {
    var _a, _b, _c;
    this.llm = (_a = init == null ? void 0 : init.llm) != null ? _a : new OpenAI2();
    this.prompt = (_b = init == null ? void 0 : init.prompt) != null ? _b : defaultSubQuestionPrompt;
    this.outputParser = (_c = init == null ? void 0 : init.outputParser) != null ? _c : new SubQuestionOutputParser();
  }
  generate(tools, query) {
    return __async(this, null, function* () {
      const toolsStr = buildToolsText(tools);
      const queryStr = query;
      const prediction = (yield this.llm.complete(
        this.prompt({
          toolsStr,
          queryStr
        })
      )).message.content;
      const structuredOutput = this.outputParser.parse(prediction);
      return structuredOutput.parsedOutput;
    });
  }
};

// src/ResponseSynthesizer.ts
var SimpleResponseBuilder = class {
  constructor(serviceContext) {
    this.llm = serviceContext.llm;
    this.textQATemplate = defaultTextQaPrompt;
  }
  getResponse(query, textChunks, parentEvent) {
    return __async(this, null, function* () {
      const input = {
        query,
        context: textChunks.join("\n\n")
      };
      const prompt = this.textQATemplate(input);
      const response = yield this.llm.complete(prompt, parentEvent);
      return response.message.content;
    });
  }
};
var Refine = class {
  constructor(serviceContext, textQATemplate, refineTemplate) {
    this.serviceContext = serviceContext;
    this.textQATemplate = textQATemplate != null ? textQATemplate : defaultTextQaPrompt;
    this.refineTemplate = refineTemplate != null ? refineTemplate : defaultRefinePrompt;
  }
  getResponse(query, textChunks, parentEvent, prevResponse) {
    return __async(this, null, function* () {
      let response = void 0;
      for (const chunk of textChunks) {
        if (!prevResponse) {
          response = yield this.giveResponseSingle(query, chunk, parentEvent);
        } else {
          response = yield this.refineResponseSingle(
            prevResponse,
            query,
            chunk,
            parentEvent
          );
        }
        prevResponse = response;
      }
      return response != null ? response : "Empty Response";
    });
  }
  giveResponseSingle(queryStr, textChunk, parentEvent) {
    return __async(this, null, function* () {
      const textQATemplate = (input) => this.textQATemplate(__spreadProps(__spreadValues({}, input), { query: queryStr }));
      const textChunks = this.serviceContext.promptHelper.repack(textQATemplate, [
        textChunk
      ]);
      let response = void 0;
      for (const chunk of textChunks) {
        if (!response) {
          response = (yield this.serviceContext.llm.complete(
            textQATemplate({
              context: chunk
            }),
            parentEvent
          )).message.content;
        } else {
          response = yield this.refineResponseSingle(
            response,
            queryStr,
            chunk,
            parentEvent
          );
        }
      }
      return response != null ? response : "Empty Response";
    });
  }
  refineResponseSingle(response, queryStr, textChunk, parentEvent) {
    return __async(this, null, function* () {
      const refineTemplate = (input) => this.refineTemplate(__spreadProps(__spreadValues({}, input), { query: queryStr }));
      const textChunks = this.serviceContext.promptHelper.repack(refineTemplate, [
        textChunk
      ]);
      for (const chunk of textChunks) {
        response = (yield this.serviceContext.llm.complete(
          refineTemplate({
            context: chunk,
            existingAnswer: response
          }),
          parentEvent
        )).message.content;
      }
      return response;
    });
  }
};
var CompactAndRefine = class _CompactAndRefine extends Refine {
  getResponse(query, textChunks, parentEvent, prevResponse) {
    return __async(this, null, function* () {
      const textQATemplate = (input) => this.textQATemplate(__spreadProps(__spreadValues({}, input), { query }));
      const refineTemplate = (input) => this.refineTemplate(__spreadProps(__spreadValues({}, input), { query }));
      const maxPrompt = getBiggestPrompt([textQATemplate, refineTemplate]);
      const newTexts = this.serviceContext.promptHelper.repack(
        maxPrompt,
        textChunks
      );
      const response = __superGet(_CompactAndRefine.prototype, this, "getResponse").call(
        this,
        query,
        newTexts,
        parentEvent,
        prevResponse
      );
      return response;
    });
  }
};
var TreeSummarize = class {
  constructor(serviceContext, summaryTemplate) {
    this.serviceContext = serviceContext;
    this.summaryTemplate = summaryTemplate != null ? summaryTemplate : defaultTreeSummarizePrompt;
  }
  getResponse(query, textChunks, parentEvent) {
    return __async(this, null, function* () {
      if (!textChunks || textChunks.length === 0) {
        throw new Error("Must have at least one text chunk");
      }
      const packedTextChunks = this.serviceContext.promptHelper.repack(
        this.summaryTemplate,
        textChunks
      );
      if (packedTextChunks.length === 1) {
        return (yield this.serviceContext.llm.complete(
          this.summaryTemplate({
            context: packedTextChunks[0],
            query
          }),
          parentEvent
        )).message.content;
      } else {
        const summaries = yield Promise.all(
          packedTextChunks.map(
            (chunk) => this.serviceContext.llm.complete(
              this.summaryTemplate({
                context: chunk,
                query
              }),
              parentEvent
            )
          )
        );
        return this.getResponse(
          query,
          summaries.map((s) => s.message.content)
        );
      }
    });
  }
};
function getResponseBuilder(serviceContext, responseMode) {
  switch (responseMode) {
    case "simple" /* SIMPLE */:
      return new SimpleResponseBuilder(serviceContext);
    case "refine" /* REFINE */:
      return new Refine(serviceContext);
    case "tree_summarize" /* TREE_SUMMARIZE */:
      return new TreeSummarize(serviceContext);
    default:
      return new CompactAndRefine(serviceContext);
  }
}
var ResponseSynthesizer = class {
  constructor({
    responseBuilder,
    serviceContext,
    metadataMode = "NONE" /* NONE */
  } = {}) {
    this.serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults();
    this.responseBuilder = responseBuilder != null ? responseBuilder : getResponseBuilder(this.serviceContext);
    this.metadataMode = metadataMode;
  }
  synthesize(query, nodesWithScore, parentEvent) {
    return __async(this, null, function* () {
      let textChunks = nodesWithScore.map(
        ({ node }) => node.getContent(this.metadataMode)
      );
      const response = yield this.responseBuilder.getResponse(
        query,
        textChunks,
        parentEvent
      );
      return new Response(
        response,
        nodesWithScore.map(({ node }) => node)
      );
    });
  }
};

// src/QueryEngine.ts
var RetrieverQueryEngine = class {
  constructor(retriever, responseSynthesizer, preFilters, nodePostprocessors) {
    this.retriever = retriever;
    const serviceContext = this.retriever.getServiceContext();
    this.responseSynthesizer = responseSynthesizer || new ResponseSynthesizer({ serviceContext });
    this.preFilters = preFilters;
    this.nodePostprocessors = nodePostprocessors || [];
  }
  applyNodePostprocessors(nodes) {
    return this.nodePostprocessors.reduce(
      (nodes2, nodePostprocessor) => nodePostprocessor.postprocessNodes(nodes2),
      nodes
    );
  }
  retrieve(query, parentEvent) {
    return __async(this, null, function* () {
      const nodes = yield this.retriever.retrieve(
        query,
        parentEvent,
        this.preFilters
      );
      return this.applyNodePostprocessors(nodes);
    });
  }
  query(query, parentEvent) {
    return __async(this, null, function* () {
      const _parentEvent = parentEvent || {
        id: uuidv45(),
        type: "wrapper",
        tags: ["final"]
      };
      const nodes = yield this.retrieve(query, _parentEvent);
      return this.responseSynthesizer.synthesize(query, nodes, _parentEvent);
    });
  }
};
var SubQuestionQueryEngine = class _SubQuestionQueryEngine {
  constructor(init) {
    var _a;
    this.questionGen = init.questionGen;
    this.responseSynthesizer = (_a = init.responseSynthesizer) != null ? _a : new ResponseSynthesizer();
    this.queryEngines = init.queryEngineTools.reduce((acc, tool) => {
      acc[tool.metadata.name] = tool.queryEngine;
      return acc;
    }, {});
    this.metadatas = init.queryEngineTools.map((tool) => tool.metadata);
  }
  static fromDefaults(init) {
    var _a, _b, _c;
    const serviceContext = (_a = init.serviceContext) != null ? _a : serviceContextFromDefaults({});
    const questionGen = (_b = init.questionGen) != null ? _b : new LLMQuestionGenerator();
    const responseSynthesizer = (_c = init.responseSynthesizer) != null ? _c : new ResponseSynthesizer({
      responseBuilder: new CompactAndRefine(serviceContext),
      serviceContext
    });
    return new _SubQuestionQueryEngine({
      questionGen,
      responseSynthesizer,
      queryEngineTools: init.queryEngineTools
    });
  }
  query(query) {
    return __async(this, null, function* () {
      const subQuestions = yield this.questionGen.generate(this.metadatas, query);
      const parentEvent = {
        id: uuidv45(),
        type: "wrapper",
        tags: ["final"]
      };
      const subQueryParentEvent = {
        id: uuidv45(),
        parentId: parentEvent.id,
        type: "wrapper",
        tags: ["intermediate"]
      };
      const subQNodes = yield Promise.all(
        subQuestions.map((subQ) => this.querySubQ(subQ, subQueryParentEvent))
      );
      const nodes = subQNodes.filter((node) => node !== null).map((node) => node);
      return this.responseSynthesizer.synthesize(query, nodes, parentEvent);
    });
  }
  querySubQ(subQ, parentEvent) {
    return __async(this, null, function* () {
      try {
        const question = subQ.subQuestion;
        const queryEngine = this.queryEngines[subQ.toolName];
        const response = yield queryEngine.query(question, parentEvent);
        const responseText = response.response;
        const nodeText = `Sub question: ${question}
Response: ${responseText}`;
        const node = new TextNode({ text: nodeText });
        return { node, score: 0 };
      } catch (error) {
        return null;
      }
    });
  }
};

// src/storage/FileSystem.ts
import _4 from "lodash";
var InMemoryFileSystem = class {
  constructor() {
    this.files = {};
  }
  writeFile(path5, content, options) {
    return __async(this, null, function* () {
      this.files[path5] = _4.cloneDeep(content);
    });
  }
  readFile(path5, options) {
    return __async(this, null, function* () {
      if (!(path5 in this.files)) {
        throw new Error(`File ${path5} does not exist`);
      }
      return _4.cloneDeep(this.files[path5]);
    });
  }
  access(path5) {
    return __async(this, null, function* () {
      if (!(path5 in this.files)) {
        throw new Error(`File ${path5} does not exist`);
      }
    });
  }
  mkdir(path5, options) {
    return __async(this, null, function* () {
      this.files[path5] = _4.get(this.files, path5, null);
    });
  }
};
function getNodeFS() {
  const fs2 = __require("fs/promises");
  return fs2;
}
var fs = null;
try {
  fs = getNodeFS();
} catch (e) {
  fs = new InMemoryFileSystem();
}
var DEFAULT_FS = fs;
function exists(fs2, path5) {
  return __async(this, null, function* () {
    try {
      yield fs2.access(path5);
      return true;
    } catch (e) {
      return false;
    }
  });
}
function walk(fs2, dirPath) {
  return __asyncGenerator(this, null, function* () {
    if (fs2 instanceof InMemoryFileSystem) {
      throw new Error(
        "The InMemoryFileSystem does not support directory traversal."
      );
    }
    const entries = yield new __await(fs2.readdir(dirPath));
    for (const entry of entries) {
      const fullPath = `${dirPath}/${entry}`;
      const stats = yield new __await(fs2.stat(fullPath));
      if (stats.isDirectory()) {
        yield* __yieldStar(walk(fs2, fullPath));
      } else {
        yield fullPath;
      }
    }
  });
}

// src/storage/constants.ts
var DEFAULT_COLLECTION = "data";
var DEFAULT_PERSIST_DIR = "./storage";
var DEFAULT_INDEX_STORE_PERSIST_FILENAME = "index_store.json";
var DEFAULT_DOC_STORE_PERSIST_FILENAME = "doc_store.json";
var DEFAULT_VECTOR_STORE_PERSIST_FILENAME = "vector_store.json";
var DEFAULT_GRAPH_STORE_PERSIST_FILENAME = "graph_store.json";
var DEFAULT_NAMESPACE = "docstore";

// src/storage/docStore/SimpleDocumentStore.ts
import _7 from "lodash";
import * as path2 from "path";

// src/storage/kvStore/SimpleKVStore.ts
import * as _5 from "lodash";
import * as path from "path";

// src/storage/kvStore/types.ts
var BaseKVStore = class {
};
var BaseInMemoryKVStore = class extends BaseKVStore {
  static fromPersistPath(persistPath) {
    throw new Error("Method not implemented.");
  }
};

// src/storage/kvStore/SimpleKVStore.ts
var SimpleKVStore = class _SimpleKVStore extends BaseKVStore {
  constructor(data) {
    super();
    this.data = data || {};
  }
  put(_0, _1) {
    return __async(this, arguments, function* (key, val, collection = DEFAULT_COLLECTION) {
      if (!(collection in this.data)) {
        this.data[collection] = {};
      }
      this.data[collection][key] = _5.clone(val);
      if (this.persistPath) {
        yield this.persist(this.persistPath, this.fs);
      }
    });
  }
  get(_0) {
    return __async(this, arguments, function* (key, collection = DEFAULT_COLLECTION) {
      let collectionData = this.data[collection];
      if (_5.isNil(collectionData)) {
        return null;
      }
      if (!(key in collectionData)) {
        return null;
      }
      return _5.clone(collectionData[key]);
    });
  }
  getAll() {
    return __async(this, arguments, function* (collection = DEFAULT_COLLECTION) {
      return _5.clone(this.data[collection]);
    });
  }
  delete(_0) {
    return __async(this, arguments, function* (key, collection = DEFAULT_COLLECTION) {
      if (key in this.data[collection]) {
        delete this.data[collection][key];
        return true;
      }
      return false;
    });
  }
  persist(persistPath, fs2) {
    return __async(this, null, function* () {
      fs2 = fs2 || DEFAULT_FS;
      let dirPath = path.dirname(persistPath);
      if (!(yield exists(fs2, dirPath))) {
        yield fs2.mkdir(dirPath);
      }
      yield fs2.writeFile(persistPath, JSON.stringify(this.data));
    });
  }
  static fromPersistPath(persistPath, fs2) {
    return __async(this, null, function* () {
      fs2 = fs2 || DEFAULT_FS;
      let dirPath = path.dirname(persistPath);
      if (!(yield exists(fs2, dirPath))) {
        yield fs2.mkdir(dirPath);
      }
      let data = {};
      try {
        let fileData = yield fs2.readFile(persistPath);
        data = JSON.parse(fileData.toString());
      } catch (e) {
        console.error(
          `No valid data found at path: ${persistPath} starting new store.`
        );
      }
      const store = new _SimpleKVStore(data);
      store.persistPath = persistPath;
      store.fs = fs2;
      return store;
    });
  }
  toDict() {
    return this.data;
  }
  static fromDict(saveDict) {
    return new _SimpleKVStore(saveDict);
  }
};

// src/storage/docStore/KVDocumentStore.ts
import _6, * as lodash from "lodash";

// src/storage/docStore/types.ts
var defaultPersistPath = `${DEFAULT_PERSIST_DIR}/${DEFAULT_DOC_STORE_PERSIST_FILENAME}`;
var BaseDocumentStore = class {
  // Save/load
  persist(persistPath = defaultPersistPath, fs2) {
  }
  // Nodes
  getNodes(nodeIds, raiseError = true) {
    return Promise.all(
      nodeIds.map((nodeId) => this.getNode(nodeId, raiseError))
    );
  }
  getNode(nodeId, raiseError = true) {
    return __async(this, null, function* () {
      let doc = yield this.getDocument(nodeId, raiseError);
      if (!(doc instanceof BaseNode)) {
        throw new Error(`Document ${nodeId} is not a Node.`);
      }
      return doc;
    });
  }
  getNodeDict(nodeIdDict) {
    return __async(this, null, function* () {
      let result = {};
      for (let index in nodeIdDict) {
        result[index] = yield this.getNode(nodeIdDict[index]);
      }
      return result;
    });
  }
};

// src/storage/docStore/utils.ts
var TYPE_KEY = "__type__";
var DATA_KEY = "__data__";
function docToJson(doc) {
  return {
    [DATA_KEY]: JSON.stringify(doc),
    [TYPE_KEY]: doc.getType()
  };
}
function jsonToDoc(docDict) {
  let docType = docDict[TYPE_KEY];
  let dataDict = JSON.parse(docDict[DATA_KEY]);
  let doc;
  if (docType === "DOCUMENT" /* DOCUMENT */) {
    doc = new Document({
      text: dataDict.text,
      id_: dataDict.id_,
      embedding: dataDict.embedding,
      hash: dataDict.hash,
      metadata: dataDict.metadata
    });
  } else if (docType === "TEXT" /* TEXT */) {
    doc = new TextNode({
      text: dataDict.text,
      id_: dataDict.id_,
      hash: dataDict.hash,
      metadata: dataDict.metadata
    });
  } else {
    throw new Error(`Unknown doc type: ${docType}`);
  }
  return doc;
}

// src/storage/docStore/KVDocumentStore.ts
var KVDocumentStore = class extends BaseDocumentStore {
  constructor(kvstore, namespace = DEFAULT_NAMESPACE) {
    super();
    this.kvstore = kvstore;
    this.nodeCollection = `${namespace}/data`;
    this.refDocCollection = `${namespace}/ref_doc_info`;
    this.metadataCollection = `${namespace}/metadata`;
  }
  docs() {
    return __async(this, null, function* () {
      let jsonDict = yield this.kvstore.getAll(this.nodeCollection);
      let docs = {};
      for (let key in jsonDict) {
        docs[key] = jsonToDoc(jsonDict[key]);
      }
      return docs;
    });
  }
  addDocuments(docs, allowUpdate = true) {
    return __async(this, null, function* () {
      for (var idx = 0; idx < docs.length; idx++) {
        const doc = docs[idx];
        if (doc.id_ === null) {
          throw new Error("doc_id not set");
        }
        if (!allowUpdate && (yield this.documentExists(doc.id_))) {
          throw new Error(
            `doc_id ${doc.id_} already exists. Set allow_update to True to overwrite.`
          );
        }
        let nodeKey = doc.id_;
        let data = docToJson(doc);
        yield this.kvstore.put(nodeKey, data, this.nodeCollection);
        let metadata = { docHash: doc.hash };
        if (doc.getType() === "TEXT" /* TEXT */ && doc.sourceNode !== void 0) {
          let refDocInfo = (yield this.getRefDocInfo(doc.sourceNode.nodeId)) || {
            nodeIds: [],
            extraInfo: {}
          };
          refDocInfo.nodeIds.push(doc.id_);
          if (_6.isEmpty(refDocInfo.extraInfo)) {
            refDocInfo.extraInfo = {};
          }
          yield this.kvstore.put(
            doc.sourceNode.nodeId,
            refDocInfo,
            this.refDocCollection
          );
          metadata.refDocId = doc.sourceNode.nodeId;
        }
        this.kvstore.put(nodeKey, metadata, this.metadataCollection);
      }
    });
  }
  getDocument(docId, raiseError = true) {
    return __async(this, null, function* () {
      let json = yield this.kvstore.get(docId, this.nodeCollection);
      if (_6.isNil(json)) {
        if (raiseError) {
          throw new Error(`docId ${docId} not found.`);
        } else {
          return;
        }
      }
      return jsonToDoc(json);
    });
  }
  getRefDocInfo(refDocId) {
    return __async(this, null, function* () {
      let refDocInfo = yield this.kvstore.get(refDocId, this.refDocCollection);
      return refDocInfo ? _6.clone(refDocInfo) : void 0;
    });
  }
  getAllRefDocInfo() {
    return __async(this, null, function* () {
      let refDocInfos = yield this.kvstore.getAll(this.refDocCollection);
      if (_6.isNil(refDocInfos)) {
        return;
      }
      return refDocInfos;
    });
  }
  refDocExists(refDocId) {
    return __async(this, null, function* () {
      return !_6.isNil(yield this.getRefDocInfo(refDocId));
    });
  }
  documentExists(docId) {
    return __async(this, null, function* () {
      return !_6.isNil(yield this.kvstore.get(docId, this.nodeCollection));
    });
  }
  removeRefDocNode(docId) {
    return __async(this, null, function* () {
      let metadata = yield this.kvstore.get(docId, this.metadataCollection);
      if (metadata === null) {
        return;
      }
      let refDocId = metadata.refDocId;
      if (_6.isNil(refDocId)) {
        return;
      }
      const refDocInfo = yield this.kvstore.get(refDocId, this.refDocCollection);
      if (!_6.isNil(refDocInfo)) {
        lodash.pull(refDocInfo.docIds, docId);
        if (refDocInfo.docIds.length > 0) {
          this.kvstore.put(refDocId, refDocInfo.toDict(), this.refDocCollection);
        }
        this.kvstore.delete(refDocId, this.metadataCollection);
      }
    });
  }
  deleteDocument(docId, raiseError = true, removeRefDocNode = true) {
    return __async(this, null, function* () {
      if (removeRefDocNode) {
        yield this.removeRefDocNode(docId);
      }
      let deleteSuccess = yield this.kvstore.delete(docId, this.nodeCollection);
      yield this.kvstore.delete(docId, this.metadataCollection);
      if (!deleteSuccess && raiseError) {
        throw new Error(`doc_id ${docId} not found.`);
      }
    });
  }
  deleteRefDoc(refDocId, raiseError = true) {
    return __async(this, null, function* () {
      let refDocInfo = yield this.getRefDocInfo(refDocId);
      if (_6.isNil(refDocInfo)) {
        if (raiseError) {
          throw new Error(`ref_doc_id ${refDocId} not found.`);
        } else {
          return;
        }
      }
      for (let docId of refDocInfo.nodeIds) {
        yield this.deleteDocument(docId, false, false);
      }
      yield this.kvstore.delete(refDocId, this.metadataCollection);
      yield this.kvstore.delete(refDocId, this.refDocCollection);
    });
  }
  setDocumentHash(docId, docHash) {
    return __async(this, null, function* () {
      let metadata = { docHash };
      yield this.kvstore.put(docId, metadata, this.metadataCollection);
    });
  }
  getDocumentHash(docId) {
    return __async(this, null, function* () {
      let metadata = yield this.kvstore.get(docId, this.metadataCollection);
      return _6.get(metadata, "docHash");
    });
  }
};

// src/storage/docStore/SimpleDocumentStore.ts
var SimpleDocumentStore = class _SimpleDocumentStore extends KVDocumentStore {
  constructor(kvStore, namespace) {
    kvStore = kvStore || new SimpleKVStore();
    namespace = namespace || DEFAULT_NAMESPACE;
    super(kvStore, namespace);
    this.kvStore = kvStore;
  }
  static fromPersistDir() {
    return __async(this, arguments, function* (persistDir = DEFAULT_PERSIST_DIR, namespace, fsModule) {
      const persistPath = path2.join(
        persistDir,
        DEFAULT_DOC_STORE_PERSIST_FILENAME
      );
      return yield _SimpleDocumentStore.fromPersistPath(
        persistPath,
        namespace,
        fsModule
      );
    });
  }
  static fromPersistPath(persistPath, namespace, fs2) {
    return __async(this, null, function* () {
      fs2 = fs2 || DEFAULT_FS;
      const simpleKVStore = yield SimpleKVStore.fromPersistPath(persistPath, fs2);
      return new _SimpleDocumentStore(simpleKVStore, namespace);
    });
  }
  persist() {
    return __async(this, arguments, function* (persistPath = path2.join(
      DEFAULT_PERSIST_DIR,
      DEFAULT_DOC_STORE_PERSIST_FILENAME
    ), fs2) {
      fs2 = fs2 || DEFAULT_FS;
      if (_7.isObject(this.kvStore) && this.kvStore instanceof BaseInMemoryKVStore) {
        yield this.kvStore.persist(persistPath, fs2);
      }
    });
  }
  static fromDict(saveDict, namespace) {
    const simpleKVStore = SimpleKVStore.fromDict(saveDict);
    return new _SimpleDocumentStore(simpleKVStore, namespace);
  }
  toDict() {
    if (_7.isObject(this.kvStore) && this.kvStore instanceof SimpleKVStore) {
      return this.kvStore.toDict();
    }
    throw new Error("KVStore is not a SimpleKVStore");
  }
};

// src/storage/indexStore/SimpleIndexStore.ts
import * as path3 from "path";

// src/storage/indexStore/KVIndexStore.ts
import _8 from "lodash";

// src/storage/indexStore/types.ts
var defaultPersistPath2 = `${DEFAULT_PERSIST_DIR}/${DEFAULT_INDEX_STORE_PERSIST_FILENAME}`;
var BaseIndexStore = class {
  persist() {
    return __async(this, arguments, function* (persistPath = defaultPersistPath2, fs2) {
    });
  }
};

// src/storage/indexStore/KVIndexStore.ts
var KVIndexStore = class extends BaseIndexStore {
  constructor(kvStore, namespace = DEFAULT_NAMESPACE) {
    super();
    this._kvStore = kvStore;
    this._collection = `${namespace}/data`;
  }
  addIndexStruct(indexStruct) {
    return __async(this, null, function* () {
      let key = indexStruct.indexId;
      let data = indexStruct.toJson();
      yield this._kvStore.put(key, data, this._collection);
    });
  }
  deleteIndexStruct(key) {
    return __async(this, null, function* () {
      yield this._kvStore.delete(key, this._collection);
    });
  }
  getIndexStruct(structId) {
    return __async(this, null, function* () {
      if (_8.isNil(structId)) {
        let structs = yield this.getIndexStructs();
        if (structs.length !== 1) {
          throw new Error("More than one index struct found");
        }
        return structs[0];
      } else {
        let json = yield this._kvStore.get(structId, this._collection);
        if (_8.isNil(json)) {
          return;
        }
        return jsonToIndexStruct(json);
      }
    });
  }
  getIndexStructs() {
    return __async(this, null, function* () {
      let jsons = yield this._kvStore.getAll(this._collection);
      return _8.values(jsons).map((json) => jsonToIndexStruct(json));
    });
  }
};

// src/storage/indexStore/SimpleIndexStore.ts
var SimpleIndexStore = class _SimpleIndexStore extends KVIndexStore {
  constructor(kvStore) {
    kvStore = kvStore || new SimpleKVStore();
    super(kvStore);
    this.kvStore = kvStore;
  }
  static fromPersistDir() {
    return __async(this, arguments, function* (persistDir = DEFAULT_PERSIST_DIR, fs2 = DEFAULT_FS) {
      const persistPath = path3.join(
        persistDir,
        DEFAULT_INDEX_STORE_PERSIST_FILENAME
      );
      return this.fromPersistPath(persistPath, fs2);
    });
  }
  static fromPersistPath(_0) {
    return __async(this, arguments, function* (persistPath, fs2 = DEFAULT_FS) {
      let simpleKVStore = yield SimpleKVStore.fromPersistPath(persistPath, fs2);
      return new _SimpleIndexStore(simpleKVStore);
    });
  }
  persist() {
    return __async(this, arguments, function* (persistPath = DEFAULT_PERSIST_DIR, fs2 = DEFAULT_FS) {
      yield this.kvStore.persist(persistPath, fs2);
    });
  }
  static fromDict(saveDict) {
    let simpleKVStore = SimpleKVStore.fromDict(saveDict);
    return new _SimpleIndexStore(simpleKVStore);
  }
  toDict() {
    if (!(this.kvStore instanceof SimpleKVStore)) {
      throw new Error("KVStore is not a SimpleKVStore");
    }
    return this.kvStore.toDict();
  }
};

// src/storage/vectorStore/SimpleVectorStore.ts
import _9 from "lodash";
import * as path4 from "path";
var LEARNER_MODES = /* @__PURE__ */ new Set([
  "svm" /* SVM */,
  "linear_regression" /* LINEAR_REGRESSION */,
  "logistic_regression" /* LOGISTIC_REGRESSION */
]);
var MMR_MODE = "mmr" /* MMR */;
var SimpleVectorStoreData = class {
  constructor() {
    this.embeddingDict = {};
    this.textIdToRefDocId = {};
  }
};
var SimpleVectorStore = class _SimpleVectorStore {
  constructor(data, fs2) {
    this.storesText = false;
    this.data = new SimpleVectorStoreData();
    this.fs = DEFAULT_FS;
    this.data = data || new SimpleVectorStoreData();
    this.fs = fs2 || DEFAULT_FS;
  }
  static fromPersistDir() {
    return __async(this, arguments, function* (persistDir = DEFAULT_PERSIST_DIR, fs2 = DEFAULT_FS) {
      let persistPath = `${persistDir}/vector_store.json`;
      return yield _SimpleVectorStore.fromPersistPath(persistPath, fs2);
    });
  }
  get client() {
    return null;
  }
  get(textId) {
    return __async(this, null, function* () {
      return this.data.embeddingDict[textId];
    });
  }
  add(embeddingResults) {
    return __async(this, null, function* () {
      var _a;
      for (let node of embeddingResults) {
        this.data.embeddingDict[node.id_] = node.getEmbedding();
        if (!node.sourceNode) {
          console.error("Missing source node from TextNode.");
          continue;
        }
        this.data.textIdToRefDocId[node.id_] = (_a = node.sourceNode) == null ? void 0 : _a.nodeId;
      }
      if (this.persistPath) {
        yield this.persist(this.persistPath, this.fs);
      }
      return embeddingResults.map((result) => result.id_);
    });
  }
  delete(refDocId) {
    return __async(this, null, function* () {
      let textIdsToDelete = Object.keys(this.data.textIdToRefDocId).filter(
        (textId) => this.data.textIdToRefDocId[textId] === refDocId
      );
      for (let textId of textIdsToDelete) {
        delete this.data.embeddingDict[textId];
        delete this.data.textIdToRefDocId[textId];
      }
      return Promise.resolve();
    });
  }
  query(query) {
    return __async(this, null, function* () {
      if (!_9.isNil(query.filters)) {
        throw new Error(
          "Metadata filters not implemented for SimpleVectorStore yet."
        );
      }
      let items = Object.entries(this.data.embeddingDict);
      let nodeIds, embeddings;
      if (query.docIds) {
        let availableIds = new Set(query.docIds);
        const queriedItems = items.filter((item) => availableIds.has(item[0]));
        nodeIds = queriedItems.map((item) => item[0]);
        embeddings = queriedItems.map((item) => item[1]);
      } else {
        nodeIds = items.map((item) => item[0]);
        embeddings = items.map((item) => item[1]);
      }
      let queryEmbedding = query.queryEmbedding;
      let topSimilarities, topIds;
      if (LEARNER_MODES.has(query.mode)) {
        [topSimilarities, topIds] = getTopKEmbeddingsLearner(
          queryEmbedding,
          embeddings,
          query.similarityTopK,
          nodeIds
        );
      } else if (query.mode === MMR_MODE) {
        let mmrThreshold = query.mmrThreshold;
        [topSimilarities, topIds] = getTopKMMREmbeddings(
          queryEmbedding,
          embeddings,
          null,
          query.similarityTopK,
          nodeIds,
          mmrThreshold
        );
      } else if (query.mode === "default" /* DEFAULT */) {
        [topSimilarities, topIds] = getTopKEmbeddings(
          queryEmbedding,
          embeddings,
          query.similarityTopK,
          nodeIds
        );
      } else {
        throw new Error(`Invalid query mode: ${query.mode}`);
      }
      return Promise.resolve({
        similarities: topSimilarities,
        ids: topIds
      });
    });
  }
  persist() {
    return __async(this, arguments, function* (persistPath = `${DEFAULT_PERSIST_DIR}/vector_store.json`, fs2) {
      fs2 = fs2 || this.fs;
      let dirPath = path4.dirname(persistPath);
      if (!(yield exists(fs2, dirPath))) {
        yield fs2.mkdir(dirPath);
      }
      yield fs2.writeFile(persistPath, JSON.stringify(this.data));
    });
  }
  static fromPersistPath(persistPath, fs2) {
    return __async(this, null, function* () {
      var _a, _b;
      fs2 = fs2 || DEFAULT_FS;
      let dirPath = path4.dirname(persistPath);
      if (!(yield exists(fs2, dirPath))) {
        yield fs2.mkdir(dirPath);
      }
      let dataDict = {};
      try {
        let fileData = yield fs2.readFile(persistPath);
        dataDict = JSON.parse(fileData.toString());
      } catch (e) {
        console.error(
          `No valid data found at path: ${persistPath} starting new store.`
        );
      }
      let data = new SimpleVectorStoreData();
      data.embeddingDict = (_a = dataDict.embeddingDict) != null ? _a : {};
      data.textIdToRefDocId = (_b = dataDict.textIdToRefDocId) != null ? _b : {};
      const store = new _SimpleVectorStore(data);
      store.persistPath = persistPath;
      store.fs = fs2;
      return store;
    });
  }
  static fromDict(saveDict) {
    let data = new SimpleVectorStoreData();
    data.embeddingDict = saveDict.embeddingDict;
    data.textIdToRefDocId = saveDict.textIdToRefDocId;
    return new _SimpleVectorStore(data);
  }
  toDict() {
    return {
      embeddingDict: this.data.embeddingDict,
      textIdToRefDocId: this.data.textIdToRefDocId
    };
  }
};

// src/storage/StorageContext.ts
function storageContextFromDefaults(_0) {
  return __async(this, arguments, function* ({
    docStore,
    indexStore,
    vectorStore,
    persistDir,
    fs: fs2
  }) {
    if (!persistDir) {
      docStore = docStore || new SimpleDocumentStore();
      indexStore = indexStore || new SimpleIndexStore();
      vectorStore = vectorStore || new SimpleVectorStore();
    } else {
      fs2 = fs2 || DEFAULT_FS;
      docStore = docStore || (yield SimpleDocumentStore.fromPersistDir(
        persistDir,
        DEFAULT_NAMESPACE,
        fs2
      ));
      indexStore = indexStore || (yield SimpleIndexStore.fromPersistDir(persistDir, fs2));
      vectorStore = vectorStore || (yield SimpleVectorStore.fromPersistDir(persistDir, fs2));
    }
    return {
      docStore,
      indexStore,
      vectorStore
    };
  });
}

// src/indices/keyword/utils.ts
import rake from "rake-modified";
function expandTokensWithSubtokens(tokens) {
  const results = /* @__PURE__ */ new Set();
  const regex = /\w+/g;
  for (let token of tokens) {
    results.add(token);
    const subTokens = token.match(regex);
    if (subTokens && subTokens.length > 1) {
      for (let w of subTokens) {
        results.add(w);
      }
    }
  }
  return results;
}
function extractKeywordsGivenResponse(response, startToken = "", lowercase = true) {
  const results = [];
  response = response.trim();
  if (response.startsWith(startToken)) {
    response = response.substring(startToken.length);
  }
  const keywords = response.split(",");
  for (let k of keywords) {
    let rk = k;
    if (lowercase) {
      rk = rk.toLowerCase();
    }
    results.push(rk.trim());
  }
  return expandTokensWithSubtokens(new Set(results));
}
function simpleExtractKeywords(textChunk, maxKeywords) {
  const regex = /\w+/g;
  let tokens = [...textChunk.matchAll(regex)].map(
    (token) => token[0].toLowerCase().trim()
  );
  const valueCounts = {};
  for (let token of tokens) {
    valueCounts[token] = (valueCounts[token] || 0) + 1;
  }
  const sortedTokens = Object.keys(valueCounts).sort(
    (a, b) => valueCounts[b] - valueCounts[a]
  );
  const keywords = maxKeywords ? sortedTokens.slice(0, maxKeywords) : sortedTokens;
  return new Set(keywords);
}
function rakeExtractKeywords(textChunk, maxKeywords) {
  const keywords = Object.keys(rake(textChunk));
  const limitedKeywords = maxKeywords ? keywords.slice(0, maxKeywords) : keywords;
  return new Set(limitedKeywords);
}

// src/indices/keyword/KeywordTableIndexRetriever.ts
var BaseKeywordTableRetriever = class {
  // A Query Keyword Extraction Prompt
  constructor({
    index,
    keywordExtractTemplate,
    queryKeywordExtractTemplate,
    maxKeywordsPerQuery = 10,
    numChunksPerQuery = 10
  }) {
    this.index = index;
    this.indexStruct = index.indexStruct;
    this.docstore = index.docStore;
    this.serviceContext = index.serviceContext;
    this.maxKeywordsPerQuery = maxKeywordsPerQuery;
    this.numChunksPerQuery = numChunksPerQuery;
    this.keywordExtractTemplate = keywordExtractTemplate || defaultKeywordExtractPrompt;
    this.queryKeywordExtractTemplate = queryKeywordExtractTemplate || defaultQueryKeywordExtractPrompt;
  }
  retrieve(query) {
    return __async(this, null, function* () {
      var _a;
      const keywords = yield this.getKeywords(query);
      const chunkIndicesCount = {};
      const filteredKeywords = keywords.filter(
        (keyword) => this.indexStruct.table.has(keyword)
      );
      for (let keyword of filteredKeywords) {
        for (let nodeId of this.indexStruct.table.get(keyword) || []) {
          chunkIndicesCount[nodeId] = ((_a = chunkIndicesCount[nodeId]) != null ? _a : 0) + 1;
        }
      }
      const sortedChunkIndices = Object.keys(chunkIndicesCount).sort((a, b) => chunkIndicesCount[b] - chunkIndicesCount[a]).slice(0, this.numChunksPerQuery);
      const sortedNodes = yield this.docstore.getNodes(sortedChunkIndices);
      return sortedNodes.map((node) => ({ node }));
    });
  }
  getServiceContext() {
    return this.index.serviceContext;
  }
};
var KeywordTableLLMRetriever = class extends BaseKeywordTableRetriever {
  getKeywords(query) {
    return __async(this, null, function* () {
      const response = yield this.serviceContext.llm.complete(
        this.queryKeywordExtractTemplate({
          question: query,
          maxKeywords: this.maxKeywordsPerQuery
        })
      );
      const keywords = extractKeywordsGivenResponse(
        response.message.content,
        "KEYWORDS:"
      );
      return [...keywords];
    });
  }
};
var KeywordTableSimpleRetriever = class extends BaseKeywordTableRetriever {
  getKeywords(query) {
    return Promise.resolve([
      ...simpleExtractKeywords(query, this.maxKeywordsPerQuery)
    ]);
  }
};
var KeywordTableRAKERetriever = class extends BaseKeywordTableRetriever {
  getKeywords(query) {
    return Promise.resolve([
      ...rakeExtractKeywords(query, this.maxKeywordsPerQuery)
    ]);
  }
};

// src/indices/keyword/KeywordTableIndex.ts
var KeywordTableRetrieverMode = /* @__PURE__ */ ((KeywordTableRetrieverMode2) => {
  KeywordTableRetrieverMode2["DEFAULT"] = "DEFAULT";
  KeywordTableRetrieverMode2["SIMPLE"] = "SIMPLE";
  KeywordTableRetrieverMode2["RAKE"] = "RAKE";
  return KeywordTableRetrieverMode2;
})(KeywordTableRetrieverMode || {});
var KeywordTableRetrieverMap = {
  ["DEFAULT" /* DEFAULT */]: KeywordTableLLMRetriever,
  ["SIMPLE" /* SIMPLE */]: KeywordTableSimpleRetriever,
  ["RAKE" /* RAKE */]: KeywordTableRAKERetriever
};
var KeywordTableIndex = class _KeywordTableIndex extends BaseIndex {
  constructor(init) {
    super(init);
  }
  static init(options) {
    return __async(this, null, function* () {
      var _a, _b;
      const storageContext = (_a = options.storageContext) != null ? _a : yield storageContextFromDefaults({});
      const serviceContext = (_b = options.serviceContext) != null ? _b : serviceContextFromDefaults({});
      const { docStore, indexStore } = storageContext;
      let indexStructs = yield indexStore.getIndexStructs();
      let indexStruct;
      if (options.indexStruct && indexStructs.length > 0) {
        throw new Error(
          "Cannot initialize index with both indexStruct and indexStore"
        );
      }
      if (options.indexStruct) {
        indexStruct = options.indexStruct;
      } else if (indexStructs.length == 1) {
        indexStruct = indexStructs[0];
      } else if (indexStructs.length > 1 && options.indexId) {
        indexStruct = yield indexStore.getIndexStruct(
          options.indexId
        );
      } else {
        indexStruct = null;
      }
      if (indexStruct && indexStruct.type !== "keyword_table" /* KEYWORD_TABLE */) {
        throw new Error(
          "Attempting to initialize KeywordTableIndex with non-keyword table indexStruct"
        );
      }
      if (indexStruct) {
        if (options.nodes) {
          throw new Error(
            "Cannot initialize KeywordTableIndex with both nodes and indexStruct"
          );
        }
      } else {
        if (!options.nodes) {
          throw new Error(
            "Cannot initialize KeywordTableIndex without nodes or indexStruct"
          );
        }
        indexStruct = yield _KeywordTableIndex.buildIndexFromNodes(
          options.nodes,
          storageContext.docStore,
          serviceContext
        );
        yield indexStore.addIndexStruct(indexStruct);
      }
      return new _KeywordTableIndex({
        storageContext,
        serviceContext,
        docStore,
        indexStore,
        indexStruct
      });
    });
  }
  asRetriever(options) {
    const _a = options != null ? options : {}, { mode = "DEFAULT" /* DEFAULT */ } = _a, otherOptions = __objRest(_a, ["mode"]);
    const KeywordTableRetriever = KeywordTableRetrieverMap[mode];
    if (KeywordTableRetriever) {
      return new KeywordTableRetriever(__spreadValues({ index: this }, otherOptions));
    }
    throw new Error(`Unknown retriever mode: ${mode}`);
  }
  asQueryEngine(options) {
    const { retriever, responseSynthesizer } = options != null ? options : {};
    return new RetrieverQueryEngine(
      retriever != null ? retriever : this.asRetriever(),
      responseSynthesizer,
      options == null ? void 0 : options.preFilters,
      options == null ? void 0 : options.nodePostprocessors
    );
  }
  static extractKeywords(text, serviceContext) {
    return __async(this, null, function* () {
      const response = yield serviceContext.llm.complete(
        defaultKeywordExtractPrompt({
          context: text
        })
      );
      return extractKeywordsGivenResponse(response.message.content, "KEYWORDS:");
    });
  }
  /**
   * High level API: split documents, get keywords, and build index.
   * @param documents
   * @param storageContext
   * @param serviceContext
   * @returns
   */
  static fromDocuments(_0) {
    return __async(this, arguments, function* (documents, args = {}) {
      let { storageContext, serviceContext } = args;
      storageContext = storageContext != null ? storageContext : yield storageContextFromDefaults({});
      serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults({});
      const docStore = storageContext.docStore;
      docStore.addDocuments(documents, true);
      for (const doc of documents) {
        docStore.setDocumentHash(doc.id_, doc.hash);
      }
      const nodes = serviceContext.nodeParser.getNodesFromDocuments(documents);
      const index = yield _KeywordTableIndex.init({
        nodes,
        storageContext,
        serviceContext
      });
      return index;
    });
  }
  /**
   * Get keywords for nodes and place them into the index.
   * @param nodes
   * @param serviceContext
   * @param vectorStore
   * @returns
   */
  static buildIndexFromNodes(nodes, docStore, serviceContext) {
    return __async(this, null, function* () {
      const indexStruct = new KeywordTable();
      yield docStore.addDocuments(nodes, true);
      for (const node of nodes) {
        const keywords = yield _KeywordTableIndex.extractKeywords(
          node.getContent("LLM" /* LLM */),
          serviceContext
        );
        indexStruct.addNode([...keywords], node.id_);
      }
      return indexStruct;
    });
  }
  insertNodes(nodes) {
    return __async(this, null, function* () {
      for (let node of nodes) {
        const keywords = yield _KeywordTableIndex.extractKeywords(
          node.getContent("LLM" /* LLM */),
          this.serviceContext
        );
        this.indexStruct.addNode([...keywords], node.id_);
      }
    });
  }
  deleteNode(nodeId) {
    const keywordsToDelete = /* @__PURE__ */ new Set();
    for (const [keyword, existingNodeIds] of Object.entries(
      this.indexStruct.table
    )) {
      const index = existingNodeIds.indexOf(nodeId);
      if (index !== -1) {
        existingNodeIds.splice(index, 1);
        if (existingNodeIds.length === 0) {
          keywordsToDelete.add(keyword);
        }
      }
    }
    this.indexStruct.deleteNode([...keywordsToDelete], nodeId);
  }
  deleteNodes(nodeIds, deleteFromDocStore) {
    return __async(this, null, function* () {
      nodeIds.forEach((nodeId) => {
        this.deleteNode(nodeId);
      });
      if (deleteFromDocStore) {
        for (const nodeId of nodeIds) {
          yield this.docStore.deleteDocument(nodeId, false);
        }
      }
      yield this.storageContext.indexStore.addIndexStruct(this.indexStruct);
    });
  }
  deleteRefDoc(refDocId, deleteFromDocStore) {
    return __async(this, null, function* () {
      const refDocInfo = yield this.docStore.getRefDocInfo(refDocId);
      if (!refDocInfo) {
        return;
      }
      yield this.deleteNodes(refDocInfo.nodeIds, false);
      if (deleteFromDocStore) {
        yield this.docStore.deleteRefDoc(refDocId, false);
      }
      return;
    });
  }
};

// src/indices/summary/SummaryIndex.ts
import _12 from "lodash";

// src/indices/summary/SummaryIndexRetriever.ts
import _11 from "lodash";

// src/indices/summary/utils.ts
import _10 from "lodash";
var defaultFormatNodeBatchFn = (summaryNodes) => {
  return summaryNodes.map((node, idx) => {
    return `
Document ${idx + 1}:
${node.getContent("LLM" /* LLM */)}
        `.trim();
  }).join("\n\n");
};
var defaultParseChoiceSelectAnswerFn = (answer, numChoices, raiseErr = false) => {
  const lineTokens = answer.split("\n").map((line) => {
    let lineTokens2 = line.split(",");
    if (lineTokens2.length !== 2) {
      if (raiseErr) {
        throw new Error(
          `Invalid answer line: ${line}. Answer line must be of the form: answer_num: <int>, answer_relevance: <float>`
        );
      } else {
        return null;
      }
    }
    return lineTokens2;
  }).filter((lineTokens2) => !_10.isNil(lineTokens2));
  return lineTokens.reduce(
    (parseResult, lineToken) => {
      try {
        let docNum = parseInt(lineToken[0].split(":")[1].trim());
        let answerRelevance = parseFloat(lineToken[1].split(":")[1].trim());
        if (docNum < 1 || docNum > numChoices) {
          if (raiseErr) {
            throw new Error(
              `Invalid answer number: ${docNum}. Answer number must be between 1 and ${numChoices}`
            );
          }
        } else {
          parseResult[docNum] = answerRelevance;
        }
      } catch (e) {
        if (raiseErr) {
          throw e;
        }
      }
      return parseResult;
    },
    {}
  );
};

// src/indices/summary/SummaryIndexRetriever.ts
var SummaryIndexRetriever = class {
  constructor(index) {
    this.index = index;
  }
  retrieve(query, parentEvent) {
    return __async(this, null, function* () {
      const nodeIds = this.index.indexStruct.nodes;
      const nodes = yield this.index.docStore.getNodes(nodeIds);
      const result = nodes.map((node) => ({
        node,
        score: 1
      }));
      if (this.index.serviceContext.callbackManager.onRetrieve) {
        this.index.serviceContext.callbackManager.onRetrieve({
          query,
          nodes: result,
          event: globalsHelper.createEvent({
            parentEvent,
            type: "retrieve"
          })
        });
      }
      return result;
    });
  }
  getServiceContext() {
    return this.index.serviceContext;
  }
};
var SummaryIndexLLMRetriever = class {
  constructor(index, choiceSelectPrompt, choiceBatchSize = 10, formatNodeBatchFn, parseChoiceSelectAnswerFn, serviceContext) {
    this.index = index;
    this.choiceSelectPrompt = choiceSelectPrompt || defaultChoiceSelectPrompt;
    this.choiceBatchSize = choiceBatchSize;
    this.formatNodeBatchFn = formatNodeBatchFn || defaultFormatNodeBatchFn;
    this.parseChoiceSelectAnswerFn = parseChoiceSelectAnswerFn || defaultParseChoiceSelectAnswerFn;
    this.serviceContext = serviceContext || index.serviceContext;
  }
  retrieve(query, parentEvent) {
    return __async(this, null, function* () {
      const nodeIds = this.index.indexStruct.nodes;
      const results = [];
      for (let idx = 0; idx < nodeIds.length; idx += this.choiceBatchSize) {
        const nodeIdsBatch = nodeIds.slice(idx, idx + this.choiceBatchSize);
        const nodesBatch = yield this.index.docStore.getNodes(nodeIdsBatch);
        const fmtBatchStr = this.formatNodeBatchFn(nodesBatch);
        const input = { context: fmtBatchStr, query };
        const rawResponse = (yield this.serviceContext.llm.complete(this.choiceSelectPrompt(input))).message.content;
        const parseResult = this.parseChoiceSelectAnswerFn(
          rawResponse,
          nodesBatch.length
        );
        const choiceNodeIds = nodeIdsBatch.filter((nodeId, idx2) => {
          return `${idx2}` in parseResult;
        });
        const choiceNodes = yield this.index.docStore.getNodes(choiceNodeIds);
        const nodeWithScores = choiceNodes.map((node, i) => ({
          node,
          score: _11.get(parseResult, `${i + 1}`, 1)
        }));
        results.push(...nodeWithScores);
      }
      if (this.serviceContext.callbackManager.onRetrieve) {
        this.serviceContext.callbackManager.onRetrieve({
          query,
          nodes: results,
          event: globalsHelper.createEvent({
            parentEvent,
            type: "retrieve"
          })
        });
      }
      return results;
    });
  }
  getServiceContext() {
    return this.serviceContext;
  }
};

// src/indices/summary/SummaryIndex.ts
var SummaryRetrieverMode = /* @__PURE__ */ ((SummaryRetrieverMode2) => {
  SummaryRetrieverMode2["DEFAULT"] = "default";
  SummaryRetrieverMode2["LLM"] = "llm";
  return SummaryRetrieverMode2;
})(SummaryRetrieverMode || {});
var SummaryIndex = class _SummaryIndex extends BaseIndex {
  constructor(init) {
    super(init);
  }
  static init(options) {
    return __async(this, null, function* () {
      var _a, _b;
      const storageContext = (_a = options.storageContext) != null ? _a : yield storageContextFromDefaults({});
      const serviceContext = (_b = options.serviceContext) != null ? _b : serviceContextFromDefaults({});
      const { docStore, indexStore } = storageContext;
      let indexStructs = yield indexStore.getIndexStructs();
      let indexStruct;
      if (options.indexStruct && indexStructs.length > 0) {
        throw new Error(
          "Cannot initialize index with both indexStruct and indexStore"
        );
      }
      if (options.indexStruct) {
        indexStruct = options.indexStruct;
      } else if (indexStructs.length == 1) {
        indexStruct = indexStructs[0];
      } else if (indexStructs.length > 1 && options.indexId) {
        indexStruct = yield indexStore.getIndexStruct(
          options.indexId
        );
      } else {
        indexStruct = null;
      }
      if (indexStruct && indexStruct.type !== "list" /* LIST */) {
        throw new Error(
          "Attempting to initialize SummaryIndex with non-list indexStruct"
        );
      }
      if (indexStruct) {
        if (options.nodes) {
          throw new Error(
            "Cannot initialize SummaryIndex with both nodes and indexStruct"
          );
        }
      } else {
        if (!options.nodes) {
          throw new Error(
            "Cannot initialize SummaryIndex without nodes or indexStruct"
          );
        }
        indexStruct = yield _SummaryIndex.buildIndexFromNodes(
          options.nodes,
          storageContext.docStore
        );
        yield indexStore.addIndexStruct(indexStruct);
      }
      return new _SummaryIndex({
        storageContext,
        serviceContext,
        docStore,
        indexStore,
        indexStruct
      });
    });
  }
  static fromDocuments(_0) {
    return __async(this, arguments, function* (documents, args = {}) {
      let { storageContext, serviceContext } = args;
      storageContext = storageContext != null ? storageContext : yield storageContextFromDefaults({});
      serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults({});
      const docStore = storageContext.docStore;
      docStore.addDocuments(documents, true);
      for (const doc of documents) {
        docStore.setDocumentHash(doc.id_, doc.hash);
      }
      const nodes = serviceContext.nodeParser.getNodesFromDocuments(documents);
      const index = yield _SummaryIndex.init({
        nodes,
        storageContext,
        serviceContext
      });
      return index;
    });
  }
  asRetriever(options) {
    const { mode = "default" /* DEFAULT */ } = options != null ? options : {};
    switch (mode) {
      case "default" /* DEFAULT */:
        return new SummaryIndexRetriever(this);
      case "llm" /* LLM */:
        return new SummaryIndexLLMRetriever(this);
      default:
        throw new Error(`Unknown retriever mode: ${mode}`);
    }
  }
  asQueryEngine(options) {
    let { retriever, responseSynthesizer } = options != null ? options : {};
    if (!retriever) {
      retriever = this.asRetriever();
    }
    if (!responseSynthesizer) {
      let responseBuilder = new CompactAndRefine(this.serviceContext);
      responseSynthesizer = new ResponseSynthesizer({
        serviceContext: this.serviceContext,
        responseBuilder
      });
    }
    return new RetrieverQueryEngine(
      retriever,
      responseSynthesizer,
      options == null ? void 0 : options.preFilters,
      options == null ? void 0 : options.nodePostprocessors
    );
  }
  static buildIndexFromNodes(nodes, docStore, indexStruct) {
    return __async(this, null, function* () {
      indexStruct = indexStruct || new IndexList();
      yield docStore.addDocuments(nodes, true);
      for (const node of nodes) {
        indexStruct.addNode(node);
      }
      return indexStruct;
    });
  }
  insertNodes(nodes) {
    return __async(this, null, function* () {
      for (const node of nodes) {
        this.indexStruct.addNode(node);
      }
    });
  }
  deleteRefDoc(refDocId, deleteFromDocStore) {
    return __async(this, null, function* () {
      const refDocInfo = yield this.docStore.getRefDocInfo(refDocId);
      if (!refDocInfo) {
        return;
      }
      yield this.deleteNodes(refDocInfo.nodeIds, false);
      if (deleteFromDocStore) {
        yield this.docStore.deleteRefDoc(refDocId, false);
      }
      return;
    });
  }
  deleteNodes(nodeIds, deleteFromDocStore) {
    return __async(this, null, function* () {
      this.indexStruct.nodes = this.indexStruct.nodes.filter(
        (existingNodeId) => !nodeIds.includes(existingNodeId)
      );
      if (deleteFromDocStore) {
        for (const nodeId of nodeIds) {
          yield this.docStore.deleteDocument(nodeId, false);
        }
      }
      yield this.storageContext.indexStore.addIndexStruct(this.indexStruct);
    });
  }
  getRefDocInfo() {
    return __async(this, null, function* () {
      const nodeDocIds = this.indexStruct.nodes;
      const nodes = yield this.docStore.getNodes(nodeDocIds);
      const refDocInfoMap = {};
      for (const node of nodes) {
        const refNode = node.sourceNode;
        if (_12.isNil(refNode)) {
          continue;
        }
        const refDocInfo = yield this.docStore.getRefDocInfo(refNode.nodeId);
        if (_12.isNil(refDocInfo)) {
          continue;
        }
        refDocInfoMap[refNode.nodeId] = refDocInfo;
      }
      return refDocInfoMap;
    });
  }
};

// src/indices/vectorStore/VectorIndexRetriever.ts
var VectorIndexRetriever = class {
  constructor({
    index,
    similarityTopK
  }) {
    this.index = index;
    this.serviceContext = this.index.serviceContext;
    this.similarityTopK = similarityTopK != null ? similarityTopK : DEFAULT_SIMILARITY_TOP_K;
  }
  retrieve(query, parentEvent, preFilters) {
    return __async(this, null, function* () {
      var _a;
      const queryEmbedding = yield this.serviceContext.embedModel.getQueryEmbedding(query);
      const q = {
        queryEmbedding,
        mode: "default" /* DEFAULT */,
        similarityTopK: this.similarityTopK
      };
      const result = yield this.index.vectorStore.query(q, preFilters);
      let nodesWithScores = [];
      for (let i = 0; i < result.ids.length; i++) {
        const nodeFromResult = (_a = result.nodes) == null ? void 0 : _a[i];
        if (!this.index.indexStruct.nodesDict[result.ids[i]] && nodeFromResult) {
          this.index.indexStruct.nodesDict[result.ids[i]] = nodeFromResult;
        }
        const node = this.index.indexStruct.nodesDict[result.ids[i]];
        nodesWithScores.push({
          node,
          score: result.similarities[i]
        });
      }
      if (this.serviceContext.callbackManager.onRetrieve) {
        this.serviceContext.callbackManager.onRetrieve({
          query,
          nodes: nodesWithScores,
          event: globalsHelper.createEvent({
            parentEvent,
            type: "retrieve"
          })
        });
      }
      return nodesWithScores;
    });
  }
  getServiceContext() {
    return this.serviceContext;
  }
};

// src/indices/vectorStore/VectorStoreIndex.ts
var VectorStoreIndex = class _VectorStoreIndex extends BaseIndex {
  constructor(init) {
    super(init);
    this.vectorStore = init.vectorStore;
  }
  /**
   * The async init function should be called after the constructor.
   * This is needed to handle persistence.
   * @param options
   * @returns
   */
  static init(options) {
    return __async(this, null, function* () {
      var _a, _b;
      const storageContext = (_a = options.storageContext) != null ? _a : yield storageContextFromDefaults({});
      const serviceContext = (_b = options.serviceContext) != null ? _b : serviceContextFromDefaults({});
      const docStore = storageContext.docStore;
      const vectorStore = storageContext.vectorStore;
      const indexStore = storageContext.indexStore;
      let indexStructs = yield indexStore.getIndexStructs();
      let indexStruct;
      if (options.indexStruct && indexStructs.length > 0) {
        throw new Error(
          "Cannot initialize index with both indexStruct and indexStore"
        );
      }
      if (options.indexStruct) {
        indexStruct = options.indexStruct;
      } else if (indexStructs.length == 1) {
        indexStruct = indexStructs[0];
      } else if (indexStructs.length > 1 && options.indexId) {
        indexStruct = yield indexStore.getIndexStruct(
          options.indexId
        );
      } else {
        indexStruct = void 0;
      }
      if (indexStruct && indexStruct.type !== "simple_dict" /* SIMPLE_DICT */) {
        throw new Error(
          "Attempting to initialize VectorStoreIndex with non-vector indexStruct"
        );
      }
      if (options.nodes) {
        indexStruct = yield _VectorStoreIndex.buildIndexFromNodes(
          options.nodes,
          serviceContext,
          vectorStore,
          docStore,
          indexStruct
        );
        yield indexStore.addIndexStruct(indexStruct);
      } else if (!indexStruct) {
        throw new Error(
          "Cannot initialize VectorStoreIndex without nodes or indexStruct"
        );
      }
      return new _VectorStoreIndex({
        storageContext,
        serviceContext,
        docStore,
        vectorStore,
        indexStruct
      });
    });
  }
  /**
   * Get the embeddings for nodes.
   * @param nodes
   * @param serviceContext
   * @param logProgress log progress to console (useful for debugging)
   * @returns
   */
  static getNodeEmbeddingResults(nodes, serviceContext, logProgress = false) {
    return __async(this, null, function* () {
      const nodesWithEmbeddings = [];
      for (let i = 0; i < nodes.length; ++i) {
        const node = nodes[i];
        if (logProgress) {
          console.log(`getting embedding for node ${i}/${nodes.length}`);
        }
        const embedding = yield serviceContext.embedModel.getTextEmbedding(
          node.getContent("EMBED" /* EMBED */)
        );
        node.embedding = embedding;
        nodesWithEmbeddings.push(node);
      }
      return nodesWithEmbeddings;
    });
  }
  /**
   * Get embeddings for nodes and place them into the index.
   * @param nodes
   * @param serviceContext
   * @param vectorStore
   * @returns
   */
  static buildIndexFromNodes(nodes, serviceContext, vectorStore, docStore, indexDict) {
    return __async(this, null, function* () {
      indexDict = indexDict != null ? indexDict : new IndexDict();
      const newNodes = nodes.filter(
        (node) => Object.entries(indexDict.nodesDict).reduce((acc, [key, value]) => {
          if (value.hash === node.hash) {
            acc = false;
          }
          return acc;
        }, true)
      );
      const embeddingResults = yield this.getNodeEmbeddingResults(
        newNodes,
        serviceContext
      );
      yield vectorStore.add(embeddingResults);
      if (!vectorStore.storesText) {
        yield docStore.addDocuments(embeddingResults, true);
      }
      for (const node of embeddingResults) {
        indexDict.addNode(node);
      }
      return indexDict;
    });
  }
  /**
   * High level API: split documents, get embeddings, and build index.
   * @param documents
   * @param storageContext
   * @param serviceContext
   * @returns
   */
  static fromDocuments(_0) {
    return __async(this, arguments, function* (documents, args = {}) {
      let { storageContext, serviceContext } = args;
      storageContext = storageContext != null ? storageContext : yield storageContextFromDefaults({});
      serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults({});
      const docStore = storageContext.docStore;
      for (const doc of documents) {
        docStore.setDocumentHash(doc.id_, doc.hash);
      }
      const nodes = serviceContext.nodeParser.getNodesFromDocuments(documents);
      const index = yield _VectorStoreIndex.init({
        nodes,
        storageContext,
        serviceContext
      });
      return index;
    });
  }
  static fromVectorStore(vectorStore, serviceContext) {
    return __async(this, null, function* () {
      if (!vectorStore.storesText) {
        throw new Error(
          "Cannot initialize from a vector store that does not store text"
        );
      }
      const storageContext = yield storageContextFromDefaults({ vectorStore });
      const index = yield _VectorStoreIndex.init({
        nodes: [],
        storageContext,
        serviceContext
      });
      return index;
    });
  }
  asRetriever(options) {
    return new VectorIndexRetriever(__spreadValues({ index: this }, options));
  }
  asQueryEngine(options) {
    const { retriever, responseSynthesizer } = options != null ? options : {};
    return new RetrieverQueryEngine(
      retriever != null ? retriever : this.asRetriever(),
      responseSynthesizer,
      options == null ? void 0 : options.preFilters,
      options == null ? void 0 : options.nodePostprocessors
    );
  }
  insertNodes(nodes) {
    return __async(this, null, function* () {
      const embeddingResults = yield _VectorStoreIndex.getNodeEmbeddingResults(
        nodes,
        this.serviceContext
      );
      const newIds = yield this.vectorStore.add(embeddingResults);
      if (!this.vectorStore.storesText) {
        for (let i = 0; i < nodes.length; ++i) {
          this.indexStruct.addNode(nodes[i], newIds[i]);
          this.docStore.addDocuments([nodes[i]], true);
        }
      } else {
        for (let i = 0; i < nodes.length; ++i) {
          if (nodes[i].getType() === "INDEX") {
            this.indexStruct.addNode(nodes[i], newIds[i]);
            this.docStore.addDocuments([nodes[i]], true);
          }
        }
      }
      yield this.storageContext.indexStore.addIndexStruct(this.indexStruct);
    });
  }
  deleteRefDoc(refDocId, deleteFromDocStore = true) {
    return __async(this, null, function* () {
      this.vectorStore.delete(refDocId);
      if (!this.vectorStore.storesText) {
        const refDocInfo = yield this.docStore.getRefDocInfo(refDocId);
        if (refDocInfo) {
          for (const nodeId of refDocInfo.nodeIds) {
            this.indexStruct.delete(nodeId);
          }
        }
        yield this.storageContext.indexStore.addIndexStruct(this.indexStruct);
      }
      if (deleteFromDocStore) {
        yield this.docStore.deleteDocument(refDocId, false);
      }
    });
  }
};

// src/readers/CSVReader.ts
import Papa from "papaparse";
var PapaCSVReader = class {
  /**
   * Constructs a new instance of the class.
   * @param {boolean} [concatRows=true] - whether to concatenate all rows into one document.If set to False, a Document will be created for each row.True by default.
   * @param {string} [colJoiner=', '] - Separator to use for joining cols per row. Set to ", " by default.
   * @param {string} [rowJoiner='\n'] - Separator to use for joining each row.Only used when `concat_rows=True`.Set to "\n" by default.
   */
  constructor(concatRows = true, colJoiner = ", ", rowJoiner = "\n", papaConfig) {
    this.concatRows = concatRows;
    this.colJoiner = colJoiner;
    this.rowJoiner = rowJoiner;
    this.papaConfig = papaConfig;
  }
  /**
   * Loads data from csv files
   * @param {string} file - The path to the file to load.
   * @param {GenericFileSystem} [fs=DEFAULT_FS] - The file system to use for reading the file.
   * @returns {Promise<Document[]>}
   */
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const fileContent = yield fs2.readFile(file, "utf-8");
      const result = Papa.parse(fileContent, this.papaConfig);
      const textList = result.data.map((row) => {
        const rowValues = Object.values(row).map((value) => String(value));
        return rowValues.join(this.colJoiner);
      });
      if (this.concatRows) {
        return [new Document({ text: textList.join(this.rowJoiner) })];
      } else {
        return textList.map((text) => new Document({ text }));
      }
    });
  }
};

// src/readers/MarkdownReader.ts
var MarkdownReader = class {
  /**
   * @param {boolean} [removeHyperlinks=true] - Indicates whether hyperlinks should be removed.
   * @param {boolean} [removeImages=true] - Indicates whether images should be removed.
   */
  constructor(removeHyperlinks = true, removeImages = true) {
    this._removeHyperlinks = removeHyperlinks;
    this._removeImages = removeImages;
  }
  /**
   * Convert a markdown file to a dictionary.
   * The keys are the headers and the values are the text under each header.
   * @param {string} markdownText - The markdown text to convert.
   * @returns {Array<MarkdownTuple>} - An array of tuples, where each tuple contains a header (or null) and its corresponding text.
   */
  markdownToTups(markdownText) {
    const markdownTups = [];
    const lines = markdownText.split("\n");
    let currentHeader = null;
    let currentText = "";
    for (const line of lines) {
      const headerMatch = line.match(/^#+\s/);
      if (headerMatch) {
        if (currentHeader) {
          if (!currentText) {
            currentHeader += line + "\n";
            continue;
          }
          markdownTups.push([currentHeader, currentText]);
        }
        currentHeader = line;
        currentText = "";
      } else {
        currentText += line + "\n";
      }
    }
    markdownTups.push([currentHeader, currentText]);
    if (currentHeader) {
      markdownTups.map((tuple) => {
        var _a;
        return [
          ((_a = tuple[0]) == null ? void 0 : _a.replace(/#/g, "").trim()) || null,
          tuple[1].replace(/<.*?>/g, "")
        ];
      });
    } else {
      markdownTups.map((tuple) => [tuple[0], tuple[1].replace(/<.*?>/g, "")]);
    }
    return markdownTups;
  }
  removeImages(content) {
    const pattern = /!{1}\[\[(.*)\]\]/g;
    return content.replace(pattern, "");
  }
  removeHyperlinks(content) {
    const pattern = /\[(.*?)\]\((.*?)\)/g;
    return content.replace(pattern, "$1");
  }
  parseTups(content) {
    let modifiedContent = content;
    if (this._removeHyperlinks) {
      modifiedContent = this.removeHyperlinks(modifiedContent);
    }
    if (this._removeImages) {
      modifiedContent = this.removeImages(modifiedContent);
    }
    return this.markdownToTups(modifiedContent);
  }
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const content = yield fs2.readFile(file, { encoding: "utf-8" });
      const tups = this.parseTups(content);
      const results = [];
      for (const [header, value] of tups) {
        if (header) {
          results.push(
            new Document({
              text: `

${header}
${value}`
            })
          );
        } else {
          results.push(new Document({ text: value }));
        }
      }
      return results;
    });
  }
};

// src/readers/NotionReader.ts
import { crawler, pageToString } from "notion-md-crawler";
var NotionReader = class {
  /**
   * Constructor for the NotionReader class
   * @param {NotionReaderOptions} options - Configuration options for the reader
   */
  constructor({ client, serializers }) {
    this.crawl = crawler({ client, serializers });
  }
  /**
   * Converts Pages to an array of Document objects
   * @param {Pages} pages - The Notion pages to convert (Return value of `loadPages`)
   * @returns {Document[]} An array of Document objects
   */
  toDocuments(pages) {
    return Object.values(pages).map((page) => {
      const text = pageToString(page);
      return new Document({ text, metadata: page.metadata });
    });
  }
  /**
   * Loads recursively the Notion page with the specified root page ID.
   * @param {string} rootPageId - The root Notion page ID
   * @returns {Promise<Pages>} A Promise that resolves to a Pages object(Convertible with the `toDocuments` method)
   */
  loadPages(rootPageId) {
    return __async(this, null, function* () {
      return this.crawl(rootPageId);
    });
  }
  /**
   * Loads recursively Notion pages and converts them to an array of Document objects
   * @param {string} rootPageId - The root Notion page ID
   * @returns {Promise<Document[]>} A Promise that resolves to an array of Document objects
   */
  loadData(rootPageId) {
    return __async(this, null, function* () {
      const pages = yield this.loadPages(rootPageId);
      return this.toDocuments(pages);
    });
  }
};

// src/readers/PDFReader.ts
import pdfParse from "pdf-parse";
var PDFReader = class {
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file);
      const data = yield pdfParse(dataBuffer);
      return [new Document({ text: data.text, id_: file })];
    });
  }
};

// src/readers/HTMLReader.ts
var HTMLReader = class {
  /**
   * Public method for this reader.
   * Required by BaseReader interface.
   * @param file Path/name of the file to be loaded.
   * @param fs fs wrapper interface for getting the file content.
   * @returns Promise<Document[]> A Promise object, eventually yielding zero or one Document parsed from the HTML content of the specified file.
   */
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file, "utf-8");
      const htmlOptions = this.getOptions();
      const content = yield this.parseContent(dataBuffer, htmlOptions);
      return [new Document({ text: content, id_: file })];
    });
  }
  /**
   * Wrapper for string-strip-html usage.
   * @param html Raw HTML content to be parsed.
   * @param options An object of options for the underlying library
   * @see getOptions
   * @returns The HTML content, stripped of unwanted tags and attributes
   */
  parseContent(_0) {
    return __async(this, arguments, function* (html, options = {}) {
      const { stripHtml } = yield import("string-strip-html");
      return stripHtml(html).result;
    });
  }
  /**
   * Wrapper for our configuration options passed to string-strip-html library
   * @see https://codsen.com/os/string-strip-html/examples
   * @returns An object of options for the underlying library
   */
  getOptions() {
    return {
      skipHtmlDecoding: true,
      stripTogetherWithTheirContents: [
        "script",
        // default
        "style",
        // default
        "xml",
        // default
        "head"
        // <-- custom-added
      ]
      // Keep the URLs for embedded links
      // cb: (tag: any, deleteFrom: number, deleteTo: number, insert: string, rangesArr: any, proposedReturn: string) => {
      //   let temp;
      //   if (
      //     tag.name === "a" &&
      //     tag.attributes &&
      //     tag.attributes.some((attr: any) => {
      //       if (attr.name === "href") {
      //         temp = attr.value;
      //         return true;
      //       }
      //     })
      //   ) {
      //     rangesArr.push([deleteFrom, deleteTo, `${temp} ${insert || ""}`]);
      //   } else {
      //     rangesArr.push(proposedReturn);
      //   }
      // },
    };
  }
};

// src/readers/SimpleDirectoryReader.ts
import _13 from "lodash";

// src/readers/DocxReader.ts
import mammoth from "mammoth";
var DocxReader = class {
  /** DocxParser */
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file);
      const { value } = yield mammoth.extractRawText({ buffer: dataBuffer });
      return [new Document({ text: value, id_: file })];
    });
  }
};

// src/readers/SimpleDirectoryReader.ts
var TextFileReader = class {
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file, "utf-8");
      return [new Document({ text: dataBuffer, id_: file })];
    });
  }
};
var FILE_EXT_TO_READER = {
  txt: new TextFileReader(),
  pdf: new PDFReader(),
  csv: new PapaCSVReader(),
  md: new MarkdownReader(),
  docx: new DocxReader(),
  htm: new HTMLReader(),
  html: new HTMLReader()
};
var SimpleDirectoryReader = class {
  loadData(_0) {
    return __async(this, arguments, function* ({
      directoryPath,
      fs: fs2 = DEFAULT_FS,
      defaultReader = new TextFileReader(),
      fileExtToReader = FILE_EXT_TO_READER
    }) {
      let docs = [];
      try {
        for (var iter = __forAwait(walk(fs2, directoryPath)), more, temp, error; more = !(temp = yield iter.next()).done; more = false) {
          const filePath = temp.value;
          try {
            const fileExt = _13.last(filePath.split(".")) || "";
            let reader = null;
            if (fileExt in fileExtToReader) {
              reader = fileExtToReader[fileExt];
            } else if (!_13.isNil(defaultReader)) {
              reader = defaultReader;
            } else {
              console.warn(`No reader for file extension of ${filePath}`);
              continue;
            }
            const fileDocs = yield reader.loadData(filePath, fs2);
            docs.push(...fileDocs);
          } catch (e) {
            console.error(`Error reading file ${filePath}: ${e}`);
          }
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield temp.call(iter));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return docs;
    });
  }
};
export {
  ALL_AVAILABLE_ANTHROPIC_MODELS,
  ALL_AVAILABLE_LLAMADEUCE_MODELS,
  ALL_AVAILABLE_OPENAI_MODELS,
  Anthropic2 as Anthropic,
  BaseDocumentStore,
  BaseEmbedding,
  BaseInMemoryKVStore,
  BaseIndex,
  BaseIndexStore,
  BaseKVStore,
  BaseNode,
  CallbackManager,
  CompactAndRefine,
  CondenseQuestionChatEngine,
  ContextChatEngine,
  DEFAULT_CHUNK_OVERLAP,
  DEFAULT_CHUNK_OVERLAP_RATIO,
  DEFAULT_CHUNK_SIZE,
  DEFAULT_COLLECTION,
  DEFAULT_CONTEXT_WINDOW,
  DEFAULT_DOC_STORE_PERSIST_FILENAME,
  DEFAULT_EMBEDDING_DIM,
  DEFAULT_FS,
  DEFAULT_GRAPH_STORE_PERSIST_FILENAME,
  DEFAULT_INDEX_STORE_PERSIST_FILENAME,
  DEFAULT_NAMESPACE,
  DEFAULT_NUM_OUTPUTS,
  DEFAULT_PADDING,
  DEFAULT_PERSIST_DIR,
  DEFAULT_SIMILARITY_TOP_K,
  DEFAULT_VECTOR_STORE_PERSIST_FILENAME,
  DefaultContextGenerator,
  DeuceChatStrategy,
  Document,
  GPT4_MODELS,
  HTMLReader,
  HistoryChatEngine,
  InMemoryFileSystem,
  IndexDict,
  IndexList,
  IndexNode,
  IndexStruct,
  IndexStructType,
  KeywordTable,
  KeywordTableIndex,
  KeywordTableLLMRetriever,
  KeywordTableRAKERetriever,
  KeywordTableRetrieverMode,
  KeywordTableSimpleRetriever,
  LLMQuestionGenerator,
  LlamaDeuce,
  MarkdownReader,
  MetadataMode,
  NodeRelationship,
  NotionReader,
  ObjectType,
  OpenAI2 as OpenAI,
  OpenAIEmbedding,
  PDFReader,
  PapaCSVReader,
  Portkey2 as Portkey,
  PromptHelper,
  Refine,
  Response,
  ResponseSynthesizer,
  RetrieverQueryEngine,
  SentenceSplitter,
  SimilarityPostprocessor,
  SimilarityType,
  SimpleChatEngine,
  SimpleChatHistory,
  SimpleDirectoryReader,
  SimpleDocumentStore,
  SimpleIndexStore,
  SimpleKVStore,
  SimpleNodeParser,
  SimpleResponseBuilder,
  SimpleVectorStore,
  SubQuestionOutputParser,
  SubQuestionQueryEngine,
  SummaryChatHistory,
  SummaryIndex,
  SummaryIndexLLMRetriever,
  SummaryIndexRetriever,
  SummaryRetrieverMode,
  TURBO_MODELS,
  TextFileReader,
  TextNode,
  Tokenizers,
  TreeSummarize,
  VectorIndexRetriever,
  VectorStoreIndex,
  VectorStoreQueryMode,
  buildToolsText,
  cjkSentenceTokenizer,
  defaultChoiceSelectPrompt,
  defaultCondenseQuestionPrompt,
  defaultContextSystemPrompt,
  defaultKeywordExtractPrompt,
  defaultQueryKeywordExtractPrompt,
  defaultRefinePrompt,
  defaultSubQuestionPrompt,
  defaultSummaryPrompt,
  defaultTextQaPrompt,
  defaultTreeSummarizePrompt,
  englishSentenceTokenizer,
  exists,
  getBiggestPrompt,
  getEmptyPromptTxt,
  getNodeFS,
  getNodesFromDocument,
  getResponseBuilder,
  getTextSplitsFromDocument,
  getTopKEmbeddings,
  getTopKEmbeddingsLearner,
  getTopKMMREmbeddings,
  globalsHelper,
  jsonToIndexStruct,
  jsonToNode,
  messagesToHistoryStr,
  parseJsonMarkdown,
  serviceContextFromDefaults,
  serviceContextFromServiceContext,
  similarity,
  storageContextFromDefaults,
  unixLineSeparator,
  unixParagraphSeparator,
  walk,
  windowsLineSeparator,
  windowsParagraphSeparator
};
